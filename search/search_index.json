{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. Introduction","text":"<p>This Codespace leverages the Dynatrace Enablement Framework, providing a robust and flexible development environment. Key features include:</p> <ul> <li>Seamless operation within GitHub Codespaces, as a remote container, or locally via Docker.</li> <li>Cross-compilation support for both AMD and ARM architectures, ensuring broad compatibility.</li> <li>Adherence to industry standards and best practices to optimize the developer experience.</li> </ul> <p>To learn more about the Dynatrace Enablement Framework and how it can enhance your development workflow, please refer to the official documentation</p> <p> </p>"},{"location":"#project-goals","title":"Project Goals","text":"The goal of this effort <p>Reduce complexity, remove friction and increase adoption of the Dynatrace Platform</p> <p>The Dynatrace Enablement Framework is a structured set of tooling and best practices designed to streamline how we deliver, maintain, and scale solutions across the Dynatrace Platform. Its core purpose is to increase platform adoption by ensuring consistent training delivery, comprehensive solution coverage, and operational efficiency.Trainings within the framework are built as GitHub Codespaces\u2014they\u2019re publicly accessible, run seamlessly across environments, and adhere to a defined set of standards to ensure quality, repeatability, and alignment across teams.</p>"},{"location":"#dynatrace-enablement-framework-in-a-nutshell","title":"Dynatrace Enablement Framework in a Nutshell","text":"<p>The Dynatrace Enablement Framework streamlines the delivery of demos and hands-on trainings for the Dynatrace Platform. It provides a unified set of tools, templates, and best practices to ensure trainings are easy to create, run anywhere, and maintain over time.</p>"},{"location":"#key-features","title":"\u2705 Key Features","text":"<ul> <li> <p>GitHub-Hosted &amp; Versioned   All trainings are managed in GitHub repositories, ensuring traceability and collaboration.</p> </li> <li> <p>Self-Service Documentation   Each repo includes its own MkDocs-powered documentation, published via GitHub Pages.</p> </li> <li> <p>Universal Base Image   A Docker image supports AMD/ARM architectures, GitHub Codespaces, VS Code Dev Containers, and contaninerized execution in any Ubuntu OS.</p> </li> <li> <p>Separation of Concerns   Modular design allows repo-specific logic without impacting the core framework.</p> </li> <li> <p>Automated Testing   GitHub Actions enable end-to-end integration tests for all trainings.</p> </li> <li> <p>Monitoring &amp; Analytics   Usage and adoption are tracked with Dynatrace for continuous improvement.</p> </li> <li> <p>Rapid Training Creation   Templates and automation help trainers launch new enablement content quickly.</p> </li> <li> <p>Centralised Maintenance   The Codespaces Synchronizer tool keeps all repositories up to date with the latest framework changes.</p> </li> </ul>"},{"location":"#benefits","title":"Benefits","text":"<ul> <li>Reduces complexity and friction for trainers and learners  </li> <li>Increases adoption and consistency  </li> <li>Scales across internal, partner, and customer enablement</li> </ul> <p>What will we do</p> <p>In this tutorial we will learn how easy it is to create an enablement using codespaces and a Kubernetes cluster!</p>"},{"location":"#support-policy","title":"Support Policy","text":"<p>Support Policy</p> <p>This is an enablement project created by the Center of Excellence - Enablement Team at Dynatrace.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p> <ul> <li>Yes! let's begin </li> </ul>"},{"location":"cleanup/","title":"Cleanup","text":"<p>Deleting the codespace from inside the container</p> <p>We like to make your life easier, for convenience there is a function loaded in the shell of the Codespace for deleting the codespace, just type <code>deleteCodespace</code>. This will trigger the deletion of the codespace.</p> <p>Another way to do this is by going to https://github.com/codespaces and delete the codespace.</p> <p>You may also want to deactivate or delete the API token needed for this lab.</p> <ul> <li>Ressources</li> </ul>"},{"location":"container-image/","title":"2. Container image","text":""},{"location":"container-image/#overview","title":"Overview","text":"<p>The Dynatrace Enablement Framework uses a custom Docker image as the foundation for all training and demo environments. This image is designed for maximum compatibility, flexibility, and ease of use across different platforms and deployment scenarios.</p>"},{"location":"container-image/#key-features","title":"Key Features","text":""},{"location":"container-image/#base-image","title":"\ud83d\uddbc\ufe0f Base Image:","text":"<p>The framework uses <code>mcr.microsoft.com/devcontainers/base:ubuntu</code> as its base image, ensuring seamless compatibility with GitHub Codespaces and Visual Studio Code Dev Containers.</p>"},{"location":"container-image/#cross-platform-support","title":"\ud83d\udcbb Cross-Platform Support:","text":"<p>The image is built to run on both AMD and ARM architectures, eliminating vendor lock-in and enabling use on a wide range of hardware.</p>"},{"location":"container-image/#local-and-cloud-execution","title":"\u2601\ufe0f Local and Cloud Execution:","text":"<ul> <li>Can be run in GitHub Codespaces for cloud-based development.</li> <li>Supports local execution on Windows, Linux, and macOS via Multipass, providing a consistent development environment regardless of the host OS.</li> </ul>"},{"location":"container-image/#dynatrace-integration","title":"Dynatrace Integration:","text":"<p>Dynatrace OneAgent FullStack and Kubernetes CloudNativeFullstack deployments work seamlessly with this deployment. All necessary components such as the CSI Driver, Webhook, ActiveGate, and OneAgents can be deployed in this image ensuring seamless monitoring and observability of the running applications.</p>"},{"location":"container-image/#tooling","title":"Tooling","text":"<p>\ud83d\udee0\ufe0f Included tooling </p> <p>The image comes with a comprehensive set of tools required for modern DevOps and cloud-native development, including:</p> <ul> <li>Helm</li> <li>Kubectl</li> <li>Kind</li> <li>Docker</li> <li>NodeJs</li> <li>K9s</li> <li>Python</li> </ul>"},{"location":"container-image/#docker-in-socket-strategy","title":"Docker-in-Socket Strategy","text":"<p>The Dynatrace Enablement Framework uses a Docker-in-Socket strategy to enable container management from within the development container. This approach allows the container to communicate directly with the Docker daemon running on the host machine by mounting the Docker socket (<code>/var/run/docker.sock</code>) into the container.</p>"},{"location":"container-image/#how-it-works","title":"How It Works","text":"<ul> <li>The <code>entrypoint.sh</code> script inside the container handles the logic for interacting with the Docker daemon.</li> <li>By sharing the Docker socket, the container can run Docker commands as if it were running directly on the host.</li> <li>This enables workflows such as building, running, and managing additional containers from within your Codespace or Dev Container.</li> </ul>"},{"location":"container-image/#benefits","title":"Benefits","text":"<ul> <li>Consistency: Ensures that Docker commands behave the same way inside the container as they do on the host.</li> <li>Flexibility: Supports advanced scenarios like running nested containers or orchestrating multi-container setups.</li> <li>Simplicity: No need to install Docker separately inside the container; it leverages the host\u2019s Docker installation.</li> </ul>"},{"location":"container-image/#example","title":"Example","text":"<p>In the <code>devcontainer.json</code>, the Docker socket is typically mounted like this:</p> <pre><code>  \"mounts\": [\"source=/var/run/docker.sock,target=/var/run/docker.sock,type=bind\"],\n</code></pre>"},{"location":"container-image/#special-container-runtime-arguments","title":"Special Container Runtime Arguments","text":"<p>The following <code>runArgs</code> configuration is used in the <code>devcontainer.json</code> file to enhance the capabilities of the development container:</p> <pre><code>\"runArgs\": [\"--init\", \"--privileged\", \"--network=host\"]\n</code></pre> <ul> <li>--init: Runs an init process inside the container to handle reaping zombie processes and signal forwarding, improving container stability.</li> <li>--privileged: Grants the container extended privileges, allowing it to access all devices on the host and perform operations typically restricted in standard containers. This is useful for scenarios that require low-level system access (e.g., running Docker inside Docker or accessing host resources).</li> <li>--network=host: Shares the host\u2019s networking stack with the container, enabling the container to use the host\u2019s network interfaces directly. This is helpful for networking tests or when services inside the container need to be accessible on the host network.</li> </ul>"},{"location":"container-image/#image-distribution","title":"Image Distribution","text":"<p>The image is hosted on Docker Hub and is crosscompiled for ARM and AMD architectures. </p>"},{"location":"container-image/#using-the-image-in-devcontainerjson","title":"Using the Image in devcontainer.json","text":"<p>The way you configure your development container depends on whether you want to use the pre-built image or build it yourself from a Dockerfile.</p>"},{"location":"container-image/#using-the-pre-built-image","title":"Using the Pre-built Image","text":"<p>To use the pre-built image, specify the \"image\" property in your devcontainer.json file:</p> <p><pre><code>  // Pulling the image from the Dockerhub, runs on AMD64 and ARM64. Pulling is normally faster.\n  \"image\":\"shinojosa/dt-enablement:v1.1\",\n</code></pre> This will pull the published image from Docker Hub and use it as the base for your Codespace or Dev Container.</p>"},{"location":"container-image/#building-the-image-with-vs-code","title":"Building the Image with VS Code","text":"<p>If you want to build the image yourself (for example, to customise it), you need to use the \"build\" section in your devcontainer.json. Uncomment or add the following: <pre><code>  // \"image\": \"shinojosa/dt-enablement\",  \n  \"build\": {    \n    \"dockerfile\": \"Dockerfile\"  }\n    },\n</code></pre></p> <p>Comment out or remove the \"image\" line. Uncomment or add the \"build\" section, pointing to your Dockerfile. This will instruct the environment to build the image locally using your Dockerfile.</p>"},{"location":"container-image/#cross-compiling-with-buildx","title":"Cross-Compiling with Buildx","text":"<p>In the <code>.devcontainer</code> folder, there is a <code>Makefile</code> that includes a <code>buildx</code> target specifically designed for cross-compiling the container image.</p> <p>To use cross-compilation:</p> <ul> <li>Make sure your host architecture is ARM.</li> <li>Run the <code>buildx</code> target from the <code>Makefile</code> to build the image for multiple architectures.</li> </ul> <p>Example usage:</p> CrossCompiling target<pre><code>make buildx\n</code></pre> <ul> <li>Let's continue</li> </ul>"},{"location":"framework/","title":"5. The Enablement Framework","text":"<p>  This section describes the structure and purpose of each part of the Codespaces Enablement Framework, as visualized in the architecture diagram.</p>"},{"location":"framework/#container-config-for-vs-code","title":"\ud83d\udfe6 Container config for VS Code","text":"<p>Defines the development container for VS Code and Codespaces. Extensions are kept to a minimum to ensure portability across platforms (ARM and AMD), so the environment can also run in plain Docker without VS Code or on different architectures.</p>"},{"location":"framework/#dockerfile","title":"Dockerfile:","text":"<p>The base image and all required tools/libraries.</p>"},{"location":"framework/#devcontainerjson","title":"devcontainer.json:","text":"<p>The main configuration file for the development container. It defines the container's settings, installed extensions, mounted volumes, arguments, environment variables, and how VS Code should start and connect to the container.</p>"},{"location":"framework/#documentation-docs","title":"\ud83d\udfe9 Documentation (<code>docs/</code>)","text":"<ul> <li>docs/:      Contains all documentation and site configuration.</li> <li>mkdocs.yaml:      Navigation and site structure for MkDocs.</li> <li>.github/workflows/deploy-ghpages.yaml:      GitHub Actions workflow to deploy documentation to GitHub Pages when a PR is merged on main.</li> </ul>"},{"location":"framework/#writing-live-documentation","title":"Writing live documentation","text":"<ul> <li> <p>installMkdocs: Installs all requirements for MkDocs (including Python dependencies from <code>docs/requirements/requirements-mkdocs.txt</code>) and then exposes the documentation locally. This is the recommended way to set up the documentation server in your dev container.</p> </li> <li> <p>exposeMkdocs: Launches the MkDocs development server on port 8000 inside your dev container, making the documentation available for live preview. The server runs in the background and supports live reload. This function is called when calling installMkdocs</p> </li> </ul>"},{"location":"framework/#deploying-to-github-pages","title":"Deploying to github pages","text":"<ul> <li>deployGhdocs: Builds and deploys the documentation to GitHub Pages using <code>mkdocs gh-deploy</code>. This publishes your latest docs to the configured GitHub Pages site.</li> </ul>"},{"location":"framework/#app-repository-apps","title":"\ud83d\udfe8 App Repository (<code>apps/</code>)","text":"<p>This directory contains the application code and sample apps to be included in the enablement. You can add multiple apps here\u2014each app should have its own subfolder inside <code>apps/</code>.</p>"},{"location":"framework/#port-allocation-and-nodeport-strategy","title":"Port Allocation and NodePort Strategy","text":"<p>When deploying applications, the framework will automatically allocate the ports exposed by the Kind Kubernetes cluster using the NodePort strategy. This is ensured by the <code>getNextFreeAppPort</code> function, which is called before deploying each app to select an available port from the defined range. By default, three ports are used, as defined in the <code>PORTS</code> variable in <code>.devcontainer/util/variables.sh</code>:</p> <pre><code>PORTS=(\"30100\" \"30200\" \"30300\")\n</code></pre> <p>These ports are mapped to your applications, making them accessible from your host machine. The NodePort strategy ensures that each app can be reached via a unique port on the cluster node.</p>"},{"location":"framework/#managing-apps-with-deployapps","title":"Managing Apps with <code>deployApps</code>","text":"<p>The framework provides a <code>deployApps</code> function to help you deploy and undeploy the applications listed in the <code>apps/</code> directory to your Kubernetes Cluster.</p> <p>Running <code>deployApps</code> without parameters will show an interactive help menu listing all available apps, their aliases, and their compatibility (AMD/ARM). Example output:</p> <p> </p>"},{"location":"framework/#to-deploy-an-app","title":"To deploy an app","text":"<ul> <li>Use any of the listed numbers, characters, or names. For example, to deploy <code>astroshop</code>, you can run:     <pre><code>deployApps 2\n# or\ndeployApps b\n# or\ndeployApps astroshop\n</code></pre></li> </ul>"},{"location":"framework/#to-undeploy-an-app","title":"To undeploy an app","text":"<ul> <li>Add <code>-d</code> as an extra argument:     <pre><code>deployApps 2 -d\n# or\ndeployApps astroshop -d \n</code></pre></li> </ul> <p>Each app folder should contain its own deployment and cleanup scripts or instructions. The <code>deployApps</code> function will call these as needed.</p>"},{"location":"framework/#running-locally","title":"\ud83d\udfe7 Running Locally","text":"<p>To quickly start a local development container, simply run:</p> <pre><code>cd .devcontainer\nmake start\n</code></pre> <p>Scripts and configuration for building and running the environment outside Codespaces:</p> <ul> <li>Makefile: Main entrypoint for local development (<code>make start</code>). It defines targets for starting, stopping, and managing the local container environment.</li> <li> <p>makefile.sh: Contains the core Bash logic for building, running, and managing the container. The Makefile sources this script to execute its targets. Key responsibilities include:</p> <ul> <li>Building the Docker image if it does not exist</li> <li>Starting the container with the correct environment, ports, and volumes</li> <li>Attaching to a running container or recreating it if stopped</li> <li>Handling cleanup and removal of containers/images</li> <li>Providing utility functions for logs, shell access, and status checks This separation allows you to keep complex logic in Bash, while the Makefile provides a simple interface for users.</li> </ul> </li> <li> <p>runlocal/: Local environment configuration, including:</p> <ul> <li><code>.env</code>: Secrets and environment variables for local runs.</li> <li><code>helper.sh</code>: Helper scripts for local setup.</li> </ul> </li> </ul>"},{"location":"framework/#github-actions-integration-tests","title":"\ud83d\udfea GitHub Actions &amp; Integration Tests","text":"<p>Automation for CI/CD and integration testing: - .github/workflows/integration-tests.yaml: Workflow for running integration tests on every Pull Request (PR) and push. The <code>main</code> branch is protected: integration tests must pass for any PR before it can be merged into <code>main</code>. - test/: Contains test scripts:     - <code>integration.sh</code>: Main integration test runner.     - <code>test_functions.sh</code>: Test utilities and functions.</p>"},{"location":"framework/#integration-test-function","title":"Integration Test Function","text":"<ul> <li>runIntegrationTests: This function triggers the integration tests for the repository by running the <code>integration.sh</code> script. It is used both locally and by the CI pipeline to ensure the environment and applications work as expected before merging changes.</li> </ul> integration.sh<pre><code>#!/bin/bash\n# Load framework\nsource .devcontainer/util/source_framework.sh\n\nprintInfoSection \"Running integration Tests for $RepositoryName\"\n\nassertRunningPod dynatrace operator\n\nassertRunningPod dynatrace activegate\n\nassertRunningPod dynatrace oneagent\n\nassertRunningPod todoapp todoapp\n\nassertRunningApp 30100\n</code></pre> <p>These assertions check that the required pods (operator, activegate, oneagent, and todoapp) are running in their respective namespaces, and that the application is accessible on the expected port (30100). If any assertion fails, the integration test will fail and block the PR from being merged.</p>"},{"location":"framework/#kubernetes-cluster","title":"\ud83d\udfeb Kubernetes Cluster","text":"<p>The Kubernetes cluster for the enablement is defined in the <code>kind-cluster.yaml</code> file. This configuration is used by Kind (Kubernetes IN Docker) to spin up a local Kubernetes cluster as a Docker container, using the Docker-in-socket strategy. The enablement container will attach to the Kind cluster, allowing you to deploy and test applications in a real Kubernetes environment.</p>"},{"location":"framework/#managing-the-kind-cluster","title":"Managing the Kind Cluster","text":"<p>The following functions are provided to manage the lifecycle of the Kind cluster:</p> <ul> <li>startKindCluster: Starts the Kind cluster. If a cluster is already running, it attaches to it; if stopped, it starts it; if none exists, it creates a new one.</li> <li>attachKindCluster: Attaches your environment to a running Kind cluster by configuring your kubeconfig for access.</li> <li>createKindCluster: Creates a new Kind cluster using the configuration in <code>kind-cluster.yaml</code>.</li> <li>stopKindCluster: Stops the Kind cluster Docker container.</li> <li>deleteKindCluster: Deletes the Kind cluster and removes all associated resources.</li> </ul> <p>These functions allow you to easily start, stop, attach, create, or delete your local Kubernetes cluster for development and testing.</p> <p>The <code>kubectl</code> client, <code>helm</code>, and <code>k9s</code> are automatically configured to work with the Kind cluster, so you can manage and observe your Kubernetes resources out of the box.</p>"},{"location":"framework/#docker-in-socket-mapping-entrypointsh","title":"\ud83d\udc33 Docker in Socket Mapping (<code>entrypoint.sh</code>)","text":"<p>This section enables the container to access the host's Docker daemon by mounting the Docker socket (<code>/var/run/docker.sock</code>). This allows the container to start and manage sibling containers, which is essential for running Kind and other Docker-based tools inside the dev environment.</p> <p>entrypoint.sh: This script is executed when the container starts. It sets up the environment, ensures the Docker socket is available, and configures any required permissions or environment variables so that Docker commands work seamlessly inside the container.</p>"},{"location":"framework/#container-post-creation-start-post-createsh-post-startsh","title":"\ud83d\udfe6 Container Post Creation &amp; Start (<code>post-create.sh</code>, <code>post-start.sh</code>)","text":"<p>Define the repository specific logic</p> <p>Within these files is where the logic is defined for automating the creation of the enablement.</p> <p>These scripts automate the setup and initialization of your development container:</p> <ul> <li> <p>post-create.sh: Runs after the Codespace or dev container is created. It loads all framework and custom functions into the shell, then executes a series of setup steps in order:</p> <p>Example <code>post-create.sh</code>: <pre><code>#!/bin/bash\n#loading functions to script\nexport SECONDS=0\nsource .devcontainer/util/source_framework.sh\n\nsetUpTerminal\n\nstartKindCluster\n\ninstallK9s\n\ndynatraceDeployOperator\n\ndeployCloudNative\n\ndeployTodoApp\n\nfinalizePostCreation\nprintInfoSection \"Your dev container finished creating\"\n</code></pre></p> </li> <li> <p>post-start.sh: Runs every time the container starts (e.g., refresh tokens, check dependencies).</p> </li> </ul>"},{"location":"framework/#core-functions-util","title":"\ud83d\udfe5 Core Functions (<code>util/</code>)","text":"<p>This directory contains the reusable shell functions, variables, and logic that power the framework. These scripts are loaded into every shell session, making their utilities available for all automation and interactive tasks.</p> <ul> <li> <p>functions.sh: The main library of core functions for the framework. It includes:</p> <ul> <li>Logging and info utilities (<code>printInfo</code>, <code>printWarn</code>, <code>printError</code>, <code>printInfoSection</code>)</li> <li>Kubernetes helpers (e.g., <code>waitForPod</code>, <code>waitForAllPods</code>, <code>waitForAllReadyPods</code>)</li> <li>Application deployment, integration, and environment management functions</li> <li>Functions for tracking codespace creation, printing greetings, and more</li> <li>All functions are loaded dynamically so you can call them from the shell or scripts</li> </ul> </li> <li> <p>source_framework.sh: Loads the framework and all utility scripts into the shell, ensuring that both core and custom functions are available in every environment (Codespaces, VS Code, or plain Docker).</p> </li> <li> <p>greeting.sh: Displays a welcome message and branding when a new shell session starts, including useful environment info and quickstart tips. You can print the greeting at any time by calling the <code>printGreeting</code> function or simply by opening a new zsh terminal.</p> </li> <li> <p>variables.sh: Central place for defining and exporting all default variables, such as image versions, port ranges, and environment-specific settings. This ensures consistency and easy configuration across the framework.</p> </li> <li> <p>variables.sh: Default variables and configuration.</p> </li> </ul>"},{"location":"framework/#custom-functions","title":"\ud83d\udfeb Custom Functions","text":"<ul> <li>my_functions.sh: This file is for defining repository-specific or custom functions. It is loaded after the core framework, so you can override or extend any behavior. For example, you can add a function to deploy your own app and call it from <code>post-create.sh</code>.</li> </ul>"},{"location":"framework/#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the Apache 2.0 License.</p> <ul> <li>Let's continue</li> </ul>"},{"location":"instantiation-types/","title":"3. Instantiation types","text":"<p>Choose the option that best fits your needs! \ud83d\ude80</p> <p>The Dynatrace Enablement Framework supports multiple ways to instantiate your development environment. You can run it in Github Codespaces, VS Code Dev Containers or local containers, in AMD or ARM architectures.  </p>"},{"location":"instantiation-types/#quick-step-by-step-guide-on-running-in","title":"\ud83c\udfc3\ud83c\udffb\u200d\u2642\ufe0f Quick step by step guide on running in...","text":""},{"location":"instantiation-types/#1-running-in-github-codespaces","title":"1. Running in \u2601\ufe0f GitHub Codespaces","text":"<ol> <li>Go to the repository hosted in github</li> <li>Click on the &lt;&gt; Code button. </li> <li>Create a new codespace using the main branch or click + New with options to customize how and where to run the Codespace within Github Cloud. </li> </ol> <p>Repository Secrets normally <code>DT_TENANT</code>, <code>DT_OPERATOR_TOKEN</code> and <code>DT_INGEST_TOKEN</code> (but not limited to) are injected automatically using GitHub Codespaces secrets. No manual setup required \u2014 these are available as environment variables inside the container.</p>"},{"location":"instantiation-types/#2-running-in-vs-code-dev-containers-or-local-container","title":"2. \ud83d\udce6 Running in VS Code Dev Containers or Local Container","text":"Key difference between instantiating a VS Code Dev Container or a local container <p>The key difference between instantiating a VS Code Dev Container and a local container lies in how each environment is created and managed: a VS Code Dev Container is launched and orchestrated directly by VS Code using the configuration specified in the devcontainer.json file, while a local container is started independently using the Makefile and runlocal script, allowing you to build and manage the container from the terminal without relying on VS Code, which is ideal for headless or automated workflows.</p> <p>The following set of instructions are for the preparation of both scenarios.</p> <ol> <li> <p>The first step is to provide the infrastructure. </p> \ud83c\udfd7\ufe0f Setting up the infrastructure <p>You may provision your infrastructure on any major cloud provider or run locally using Multipass.</p> <p>Minimum requirements for a cloud or local machine:</p> <ol> <li>Operating System: Ubuntu LTS (22.04 or 24.04 recommended)</li> <li>CPU &amp; Memory: The required resources depend on your workloads. As a general guideline, refer to the <code>hostRequirements</code> section in the <code>.devcontainer.json</code> file. A typical setup with 4 CPU cores and 16 GB RAM is sufficient for most use cases.</li> <li>Network Ports: Ensure the following ports are open for inbound connections:<ul> <li><code>22</code> (SSH)</li> <li><code>30100</code>, <code>30200</code>, <code>30300</code> (for application access; each deployed app is exposed via Kubernetes NodePort)</li> </ul> </li> </ol> </li> <li> <p>SSH into the host</p> </li> <li> <p>Clone the git repository</p> </li> <li> <p>Setting up the secrets:      Make sure the secrets are defined as environment variables. VS Code needs to read the secrets as an environment variable, and the local container approach does not need VS Code. Hence we create a file under <code>.devcontainer/runlocal/.env</code> that works for both approaches.</p> Sample <code>.env</code> file <p>You can copy and paste the contents of the sample into <code>.devcontainer/runlocal/.env</code>. Verify that you have entered all needed secrets for the training. These are defined in the <code>secrets</code> section of the .devcontainer.json<code>file. If the repository does not need secrets, just create an empty</code>.env` file.</p> .devcontainer/runlocal/.env<pre><code># Environment variables\n\n# Mapping of the Secrets defined in the .devcontainer.json file\n# Dynatrace Tenant\nDT_TENANT=https://abc123.apps.dynatrace.com\n\n# Dynatrace Operator Token\nDT_OPERATOR_TOKEN=dt0c01.XXXXXX\n#it will be created automatically when adding a new Cluster over the UI. It contains the following permissions: 'Create ActiveGate tokens' 'Read entities' 'Read settings' 'Write settings' 'Access probrem and event feed, metrics and topology' 'PaaS Integration - installer download\n\n#Dynatrace Ingest Token\nDT_INGEST_TOKEN=dt0c01.YYYYYY\n# it will be created automatically when adding a new Cluster over the UI. It contains the following permissions: 'Ingest logs' 'Ingest metrics' 'Ingest OpenTelemetry traces'\n\n# Add any other environment variables as needed\n</code></pre> </li> <li> <p>Prerequisites: <code>make</code> and <code>docker</code> is installed on the host and the user has access to it.</p> Verify prerequisites with <code>checkHost</code> <p>There is a sample function that helps you verify the requirements are met and if not it offers to install them for you if needed.  <pre><code>source .devcontainer/util/source_framework.sh &amp;&amp; checkHost\n</code></pre> </p> </li> </ol> <p>Le't's launch the enablement</p> <p>You are all set, we can launch the enablement either with <code>VS Code</code> as a dev container or with <code>make</code> as a plain docker container.</p>"},{"location":"instantiation-types/#2-a-running-as-dev-container-with-vs-code","title":"2. a. \ud83d\udce6 \ud83d\udda5\ufe0f Running as dev container with VS Code","text":"<ol> <li>Let's tell VS Code to read the secrets as environment variables from an <code>.env</code>file. Modify the <code>runArgs</code> in <code>.devcontainer/devcontainer.json</code> and add <code>\"--env-file\", \".devcontainer/runlocal/.env\"</code>like the following:     <pre><code>\"runArgs\": [\"--init\", \"--privileged\", \"--network=host\", \"--env-file\", \".devcontainer/runlocal/.env\"]\n</code></pre></li> <li>This ensures all variables in <code>.devcontainer/runlocal/.env</code> are available inside the container.</li> <li>Open the folder in VS Code and use the Dev Containers extension to \"Reopen in Container\". VS Code will use the <code>.devcontainer/devcontainer.json</code> definition to build and start the environment for you.</li> <li>You can rebuild the container at any time by typing <code>[CTRL] + Shift P &gt; Dev Containers: Rebuild and reopen in container</code></li> </ol>"},{"location":"instantiation-types/#2-b-running-as-local-container-with-make","title":"2. b. \ud83d\udce6 \ud83d\udc33 Running as local container with make","text":"<ol> <li>Navigate to <code>.devcontainer</code> folder and run:     <pre><code>make start\n</code></pre></li> <li> <p>This will build and launch the container. All ports, volumes, and environment variables are set up automatically.</p> <p>Protip: create a new Terminal</p> <p>For attaching a new Terminal to the container, just type <code>make start</code>.</p> </li> <li> <p>Secrets and environment variables are loaded from <code>.devcontainer/runlocal/.env</code>. </p> </li> <li>The <code>makefile.sh</code> script passes the variables to Docker at runtime such as arguments, volume mounts and port-forwarding. The devcontainer.json file is not used with this set-up.</li> <li>For more details, see the Local Container Details section below.</li> </ol>"},{"location":"instantiation-types/#instantiation-types","title":"Instantiation Types","text":""},{"location":"instantiation-types/#1-github-codespaces","title":"1. \u2601\ufe0f GitHub Codespaces","text":"<ul> <li>One-click cloud dev environments </li> <li>No local setup required\u2014just click  </li> <li>Learn more about Codespaces</li> </ul>"},{"location":"instantiation-types/#2-vs-code-dev-containers","title":"2. \ud83d\udda5\ufe0f VS Code Dev Containers","text":"<ul> <li>Use the Dev Containers extension for a seamless local experience in VS Code</li> <li>All configuration is in <code>.devcontainer/devcontainer.json</code></li> <li>Supports secrets, port forwarding, and post-create hooks</li> </ul>"},{"location":"instantiation-types/#3-local-container","title":"3. \ud83d\udc33 Local Container","text":"<ul> <li>Run the same environment on your machine using Docker.</li> <li>Easiest way: just run <code>make start</code> in the <code>.devcontainer</code> folder.</li> <li>This will build and launch the container if needed, or attach to it if already running.</li> <li>All ports, volumes, and environment variables are set up for you automatically.</li> </ul>"},{"location":"instantiation-types/#quick-comparison","title":"\u26a1 Quick Comparison","text":"Type Runs On VS Code Needed Fast Start Customizable Secrets Handling Port Forwarding Best For \u2601\ufe0f Codespaces GitHub Cloud \u274c \u2705 \u274c Auto-injected Auto Quick onboarding, demos \ud83d\udda5\ufe0f VS Code DevContainer Provided Infrastructure \u2705 \u2705 \u2705 Auto/manual Auto Full-featured local dev \ud83d\udc33 Local Container Provided Infrastructure \u274c \u2705 \u2705 Manual/<code>.env</code> Manual/Makefile Reproducible local dev"},{"location":"instantiation-types/#secrets-environment","title":"\ud83d\udd10 Secrets &amp; Environment","text":"<p>Secrets and environment variables are handled differently depending on the instantiation type:</p> Instantiation Type How Secrets Are Provided Where to Configure/Set Notes \u2601\ufe0f Codespaces Auto-injected as environment variables from GitHub Codespaces secrets GitHub repository &gt; Codespaces secrets No manual setup; secrets available at container start \ud83d\udda5\ufe0f VS Code Dev Containers Passed as environment variables via <code>runArgs</code> and <code>.env</code> file <code>.devcontainer/devcontainer.json</code>, <code>.devcontainer/runlocal/.env</code> Edit/add <code>.devcontainer/runlocal/.env</code> for local secrets; <code>runArgs</code> must include <code>--env-file</code> \ud83d\udc33 Local Container Loaded from <code>.devcontainer/runlocal/.env</code> file and passed to Docker at runtime by <code>makefile.sh</code> <code>.devcontainer/runlocal/.env</code>, <code>makefile.sh</code> Run <code>make start</code> in <code>.devcontainer</code>; secrets loaded at container start"},{"location":"instantiation-types/#running-locally","title":"\ud83c\udfe0 Running locally","text":""},{"location":"instantiation-types/#using-multipass-for-local-development","title":"Using Multipass for Local Development","text":"<p>Multipass is a lightweight VM manager from Canonical that makes it easy to launch and manage Ubuntu virtual machines on macOS, Windows, and Linux. This is especially useful if you want to run the framework in a clean, reproducible Ubuntu environment without dual-booting or using a full desktop VM.</p> <p>Why use Multipass?</p> <ul> <li>Ensures compatibility with Ubuntu-based dev containers and scripts</li> <li>Isolates your development environment from your host OS</li> <li>Quick to launch, easy to reset or remove</li> </ul>"},{"location":"instantiation-types/#basic-usage","title":"Basic usage","text":"<ul> <li>Install Multipass (instructions) </li> <li>Launch an Ubuntu VM: <pre><code>multipass launch --name enablement --disk 30G --cpus 8 --memory 32G\nmultipass shell dt-dev\n</code></pre></li> </ul> <p>Mounting Volumes on Multipass</p> <p>You can mount folders from your host into the VM using <code>multipass mount</code> if you want to edit code locally but run containers in the VM. For example in the following example we are creating a VM mounting the folder <code>enablement</code> where you have all repositories of the enablement framework you want to use.  <pre><code>multipass launch --name enablement --disk 30G --cpus 8 --memory 32G --mount  /Users/sergio.hinojosa/repos/enablement:/home/ubuntu/enablement\n</code></pre></p> <ul> <li>Let's continue</li> </ul>"},{"location":"monitoring/","title":"9. Monitoring","text":"<p>Monitoring is a critical aspect of maintaining quality, reliability, and visibility across all repositories and their instantiations in the enablement framework. By tracking usage and interactions, we ensure that every codespace and its associated resources are operating as expected and delivering value.</p>"},{"location":"monitoring/#why-monitoring-matters","title":"\ud83d\udce1 Why Monitoring Matters","text":"<ul> <li>Visibility: Gain insights into how repositories and codespaces are being used and adopted.</li> <li>Quality Assurance: Detect issues early and ensure that all deployments meet expected standards.</li> <li>Business Insights: Understand usage patterns and derive business value from operational data.</li> <li>Showcase Best Practices: Demonstrate the power of Dynatrace by monitoring our own codespaces (\u201cDrink your own Champagne\u201d principle).</li> </ul>"},{"location":"monitoring/#monitoring-approach","title":"Monitoring Approach","text":"<ul> <li> <p>GitHub Pages &amp; Agentless RUM:   Every codespace is associated with a GitHub Page. For each GitHub Page, an agentless Real User Monitoring (RUM) application is created, enabling end-to-end visibility into user interactions and performance.</p> </li> <li> <p>Automated Tracking on Creation:   When a new codespace is instantiated, the <code>finalizePostCreation</code> function sends a JSON payload to codespaces-tracker.whydevslovedynatrace.com/api/receive.  </p> </li> <li>Only requests with the correct authentication header are accepted.</li> <li> <p>This payload contains metadata about the codespace, its repository, and its usage context.</p> </li> <li> <p>Codespaces-Tracker Service:   The Codespaces-Tracker is a Spring Boot application deployed on a GKE (Google Kubernetes Engine) cluster with three replicas for high availability.</p> </li> <li>It processes incoming payloads, enriches them with geo-information, and logs the json payload.</li> <li>The monitoring OneAgent generates BizEvents from the pods logs, enabling advanced business-related log use cases and analytics.</li> </ul>"},{"location":"monitoring/#benefits","title":"Benefits","text":"<ul> <li>Comprehensive Monitoring:   All codespaces and their GitHub Pages are monitored for activity, performance, and adoption.</li> <li>Enhanced Observability:   Real-time data collection and enrichment provide actionable insights for both technical and business stakeholders.</li> <li>Demonstration of Dynatrace Capabilities:   By monitoring our own codespaces, we showcase Dynatrace\u2019s observability features in real-world scenarios.</li> </ul>"},{"location":"monitoring/#implementation","title":"Implementation","text":""},{"location":"monitoring/#codespaces-instantiations","title":"\ud83c\udf0e Codespaces Instantiations","text":"<p>All codespace instantiations are monitored by sending a signal to the Codespaces-Tracker service running in the GKE cluster. This is achieved through the <code>verifyCodespaceCreation</code> function, which is responsible for validating the successful creation of a codespace. </p> <ul> <li>verifyCodespaceCreation:   This function checks that the codespace environment has been set up correctly and all required components are running. Once verification is complete, it calls the <code>postCodespaceTracker</code> function.</li> <li>postCodespaceTracker:   This function sends a JSON payload containing metadata about the codespace (such as repository name, user, and environment details) to the Codespaces-Tracker API endpoint. The payload is authenticated and enriched with geo-information, and BizEvents are generated from the logs for further analysis.</li> </ul>"},{"location":"monitoring/#github-pages","title":"\ud83d\udcca GitHub Pages","text":"<p>GitHub Pages are monitored using Dynatrace Agentless Real User Monitoring (RUM):</p> <ul> <li>An agentless RUM snippet is injected into the <code>main.html</code> template located in the <code>overrides</code> folder. This ensures that every page load is tracked for user interactions and performance metrics.</li> <li>Additionally, each markdown page includes a JavaScript snippet at the top that sends a BizEvent with the name of the page to Dynatrace. This allows for detailed tracking of user navigation and engagement across the documentation.</li> </ul>"},{"location":"monitoring/#learn-more","title":"Learn More","text":"<ul> <li>Dynatrace Agentless RUM Documentation</li> <li>Business Events with Dynatrace</li> </ul> <ul> <li>Let's continue</li> </ul>"},{"location":"resources/","title":"10. Resources","text":"<p>Below you'll find a curated list of resources to help you get the most out of Dynatrace, Codespaces, and modern development best practices. These links will help you deepen your understanding, improve your workflow, and stay up-to-date with the latest trends.</p>"},{"location":"resources/#get-started-with-dynatrace","title":"\ud83d\ude80 Get Started with Dynatrace","text":"<ul> <li>Create a Free Trial in Dynatrace</li> <li>Dynatrace documentation</li> </ul>"},{"location":"resources/#dynatrace-news-community","title":"\ud83d\udcf0 Dynatrace News &amp; Community","text":"<ul> <li>Dynatrace Blog</li> <li>Dynatrace Community</li> </ul>"},{"location":"resources/#coding-best-practices","title":"\ud83d\udca1 Coding Best Practices","text":"<ul> <li>Coding Best Practices (Dynatrace Docs)</li> <li>Separation of Concerns (Wikipedia)</li> <li>GitHub Flow: Simple Git Branching Model</li> </ul>"},{"location":"resources/#git-strategies-collaboration","title":"\ud83d\udee0\ufe0f Git Strategies &amp; Collaboration","text":"<ul> <li>Git Strategies and Workflows</li> <li>Pull Requests and Code Reviews</li> </ul>"},{"location":"resources/#containerization-cloud-native-principles","title":"\ud83c\udfd7\ufe0f Containerization &amp; Cloud-Native Principles","text":"<ul> <li>Container Design Principles (Docker)</li> <li>Kubernetes Basics</li> <li>Why Codespaces? (GitHub Docs)</li> </ul>"},{"location":"resources/#enhancing-user-experience","title":"\ud83c\udfa8 Enhancing User Experience","text":"<ul> <li>User Experience Best Practices (NNG)</li> <li>Agentless Real User Monitoring (Dynatrace)</li> </ul>"},{"location":"resources/#observability-business-insights","title":"\ud83d\udcc8 Observability &amp; Business Insights","text":"<ul> <li>Business Events in Dynatrace</li> <li>Observability Explained (Dynatrace Blog)</li> </ul> <p>Explore these resources to become more effective with Dynatrace, Codespaces, and modern software engineering!</p> <ul> <li>What's Next? </li> </ul>"},{"location":"synchronizer/","title":"7. Synchronizer","text":""},{"location":"synchronizer/#7-synchronizer","title":"7. Synchronizer","text":"<p>Codespaces Synchronizer \ud83d\udd01 </p> <p>Maintaining and updating multiple repositories can be complex and time-consuming. To address this, we developed the codespaces-synchronizer, a tool designed to keep all repositories using the framework up-to-date with minimal manual intervention.  </p>"},{"location":"synchronizer/#overview","title":"Overview","text":"<p>The synchronizer operates from a host machine where all target repositories are cloned. It leverages bash scripting and <code>rsync</code> to automate repository management tasks, including updates, migrations, tagging, and branch protection. The synchronizer is composed of two main files:</p> <ul> <li><code>synch_functions.sh</code>: Contains all core logic and reusable functions for repository operations.</li> <li><code>run.sh</code>: Entry point script that loads the framework and orchestrates the synchronization process by invoking functions from <code>synch_functions.sh</code>.</li> </ul>"},{"location":"synchronizer/#key-use-cases","title":"Key Use Cases","text":"<ul> <li>Update repositories: Propagate framework or configuration changes across multiple repositories.</li> <li>Migrate repositories: Move or refactor repositories while preserving history and structure.</li> <li>Create Tags, Versions, and Releases: Automate versioning and release management.</li> <li>Protect branches and test workflows: Enforce branch protection rules and validate workflows.</li> </ul>"},{"location":"synchronizer/#requirements","title":"Requirements","text":"<ul> <li>A host machine with all target repositories cloned locally.</li> <li>GitHub permissions to create branches and pull requests.</li> <li>Bash terminal access.</li> <li><code>rsync</code> installed on the host.</li> </ul>"},{"location":"synchronizer/#strategies-for-updating-and-migrating-repos","title":"Strategies for Updating and Migrating Repos","text":"<ul> <li>Cherry-pick: Selectively apply commits from the synchronizer remote repository.</li> <li>Rsync: Efficiently synchronize files and directories between repositories (prefered approach).</li> </ul>"},{"location":"synchronizer/#how-it-works","title":"How It Works","text":"<ol> <li>Initialization: <code>run.sh</code> sets up environment variables and loads <code>synch_functions.sh</code>.</li> <li>Repository Selection: The synchronizer can operate on all repositories or a specified subset.</li> <li>Function Execution: Core functions (such as updating files, creating tags, or migrating content) are executed in batch across repositories.</li> <li>Automation: Common git operations (checkout, pull, commit, push, PR creation, verify PR, merge PR) are automated, reducing manual effort and risk of errors.</li> </ol> <ul> <li>Let's continue</li> </ul>"},{"location":"template/","title":"4. Codespaces Template","text":"<p>The Enablement Codespaces Template</p> <p> The Enablement Codespaces Template is a ready-to-use GitHub repository designed to help you create, customize, and deliver hands-on enablements using GitHub Codespaces. It provides a robust starting point for professors, trainers, and solution architects to build interactive learning environments with minimal setup.</p>"},{"location":"template/#what-is-the-codespaces-template","title":"\ud83d\ude80 What is the Codespaces Template?","text":"<p>This template repository provides:</p> <ul> <li>A pre-configured <code>.devcontainer</code> for instant Codespaces launches</li> <li>Example documentation and structure for enablement content</li> <li>GitHub Actions for CI/CD and documentation deployment</li> <li>Integration with Dynatrace and other cloud-native tools</li> <li>A clean starting point for your own enablement projects</li> </ul>"},{"location":"template/#repository-overview","title":"\ud83d\udce6 Repository Overview","text":"<p>Main features:</p> <ul> <li>.devcontainer/: All configuration for Codespaces and local dev containers</li> <li>docs/: MkDocs-based documentation, ready to extend</li> <li>.github/workflows/: CI/CD for integration tests and GitHub Pages deployment</li> <li>README.md: Project overview and quickstart</li> <li>mkdocs.yaml: Navigation and site configuration</li> </ul> <p>For a full file/folder breakdown, see the repository on GitHub.</p>"},{"location":"template/#how-to-use-the-template","title":"\ud83d\udcdd How to Use the Template","text":"<ol> <li>Create your own enablement repository<ul> <li>Click \"Use this template\" on the GitHub repo</li> <li>Name your new repository and clone it locally</li> </ul> </li> <li>Customize the content<ul> <li>Edit the <code>docs/</code> folder to add your enablement instructions, labs, and resources</li> <li>Update <code>.devcontainer/devcontainer.json</code> to add dependencies or secrets as needed</li> </ul> </li> <li>Launch in Codespaces<ul> <li>Click the Code button in your repo and select \"Open with Codespaces\"</li> <li>Your environment will be ready in seconds, with all tools and docs pre-installed</li> </ul> </li> <li>Publish documentation<ul> <li>The <code>installMKdocs</code> function installs MkDocs inside the container and serves the documentation locally on port 8000, making it easy and enjoyable to write and preview your documentation without hassle.</li> <li>Push changes to <code>main</code> to trigger GitHub Pages deployment (see Actions tab)</li> <li>Your docs will be live at <code>https://&lt;your-org&gt;.github.io/&lt;your-repo&gt;/</code></li> </ul> </li> </ol>"},{"location":"template/#todos-in-the-codebase","title":"\ud83d\udcdd TODOs in the Codebase","text":"<p>Throughout the template repository, you will find <code>TODO</code> comments in various files. These are designed to guide you step-by-step as you create your own enablements\u2014reminding you where to add content, configure secrets, or customize scripts.</p> <p>Tip: To make working with TODOs easier, install a TODO highlighting extension in VS Code, such as TODO Highlight or TODO Tree. These extensions help you quickly find and manage all TODOs in your project.</p> <p>By following and resolving these TODOs, you can efficiently adapt the template to your specific enablement scenario.</p>"},{"location":"template/#who-is-this-for","title":"\ud83e\uddd1\u200d\ud83c\udfeb Who is this for?","text":"<ul> <li>Professors and trainers creating hands-on labs</li> <li>Solution architects building demo environments</li> <li>Anyone who wants a fast, reproducible Codespaces-based enablement</li> </ul>"},{"location":"template/#documentation-resources","title":"\ud83d\udcda Documentation &amp; Resources","text":"<ul> <li>Template Repository</li> <li>How to use the codespaces template</li> </ul> <ul> <li>Let's continue</li> </ul>"},{"location":"testing/","title":"8. Testing","text":"<p>Quality Assurance</p> <p>To maintain high standards across all repositories using the enablement framework, a robust testing strategy is enforced. This ensures that every repository remains reliable, consistent, and production-ready.</p>"},{"location":"testing/#integration-testing-on-pull-requests","title":"\ud83e\uddea Integration Testing on Pull Requests","text":"<ul> <li> <p>Automated Integration Tests:   Every repository must have integration tests that run automatically on every Pull Request (PR). This guarantees that new changes do not break existing functionality.</p> </li> <li> <p>integration.sh:   The core of the testing process is the <code>integration.sh</code> script. This script is adapted for each repository and is triggered by a GitHub Actions workflow on every PR.  </p> </li> <li>The workflow provisions a full Codespace environment, deploying all required applications and dependencies.</li> <li> <p>Once the environment is ready, <code>integration.sh</code> runs a series of assertions to verify that applications and pods are running as expected in their respective namespaces.</p> </li> <li> <p>On-Demand Testing:   Integration tests can also be executed manually at any time using the <code>runIntegrationTests</code> function, providing flexibility for developers to validate changes before submitting a PR.</p> </li> </ul>"},{"location":"testing/#integration-test-example","title":"Integration Test example","text":"integration.sh<pre><code>#!/bin/bash\n# Load framework\nsource .devcontainer/util/source_framework.sh\n\nprintInfoSection \"Running integration Tests for $RepositoryName\"\n\nassertRunningPod dynatrace operator\n\nassertRunningPod dynatrace activegate\n\nassertRunningPod dynatrace oneagent\n\nassertRunningPod todoapp todoapp\n\nassertRunningApp 30100\n</code></pre>"},{"location":"testing/#git-strategy","title":"Git Strategy","text":"<p>Git Strategy &amp; Github Actions Workflow</p> <p> </p>"},{"location":"testing/#branch-protection","title":"\ud83d\udd12 Branch Protection","text":"<p>Main Branch Protection:   The <code>main</code> branch is protected and will only accept PRs that pass all integration tests. This ensures that only thoroughly tested code is merged, maintaining the integrity of the repository.</p>"},{"location":"testing/#integration-test-badges","title":"\ud83d\udee1\ufe0f Integration Test Badges","text":"<p>All repositories in the enablement framework display an integration test badge to show the current status of their automated tests. This badge provides immediate visibility into the health of each repository.</p> <p>For example, the badge for this repository is:</p> <p> </p> <p>You can find a table with all enablement framework repositories and their current integration test status in the README section of this repository.</p> <p>By following these standards, the enablement framework enforces continuous quality assurance and reliability across all managed repositories.</p> <ul> <li>Let's continue</li> </ul>"},{"location":"user-experience/","title":"6. User Experience","text":"<p>Maximizing User Experience with ease of use, best practices, readable code, devops tooling and more...</p> <p> </p> <p>To maximize adoption and maintain the Dynatrace public image\u2014particularly among DevOps stakeholders\u2014repositories leveraging the enablement framework should adhere to the following best practices.</p> <ul> <li>Present all materials and interfaces in a professional and consistent manner.</li> <li>Ensure the project is governed by a clear and recognized open source license.</li> <li>Tag stable releases to provide clear versioning and facilitate reliable adoption.</li> <li>Maintain comprehensive and up-to-date changelogs to document project evolution.</li> <li>Structure code for readability and scalability, supporting both maintainability and future growth.</li> <li>Provide clean, well-organized, and accessible documentation for all users.</li> <li>Respond promptly and constructively to issues and community feedback.</li> <li>Use inclusive language throughout documentation and communications.</li> <li>Display relevant badges, such as build status, license, and coverage, to communicate project health and transparency.</li> <li>Incorporate recognizable logos to reinforce project identity.</li> <li>Offer interactive, hands-on training resources to accelerate onboarding and skill development.</li> <li>Recommend tools such as p10k, k9s, and zsh to further enhance the DevOps experience.</li> </ul> <p>By following these guidelines, the framework remains accessible, professional, and appealing to the broader DevOps and open source communities.</p>"},{"location":"user-experience/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"user-experience/#navigating-the-kubernetes-cluster-like-butter","title":"\ud83e\uddc8 Navigating the Kubernetes Cluster Like Butter","text":"<p>One of the most efficient ways to interact with your Kubernetes cluster is by using <code>k9s</code>, a terminal-based UI that streamlines cluster management and troubleshooting.</p> <p>K9s in action</p> <p> </p> <p>Getting Started with k9s:</p> <ul> <li>Launch <code>k9s</code> by simply running <code>k9s</code> in your terminal (it comes pre-installed in the Codespaces Enablement Framework).</li> <li>The interface provides a real-time, interactive view of all your Kubernetes resources\u2014pods, deployments, services, and more.</li> <li>Use the arrow keys to navigate, <code>/</code> to filter resources, and <code>:</code> to enter commands (e.g., <code>:ctx</code> to switch contexts, <code>:ns</code> to change namespaces, <code>:pod</code>to list pods, <code>:svc</code> to list services, <code>:dynakube</code> to list dynakubes)</li> <li>Press <code>d</code> to describe a resource, <code>l</code> to view logs, and <code>s</code> to open a shell into a pod.</li> <li>Press <code>0</code> Zero to list all resources, namespaces, services</li> <li>All actions are keyboard-driven, making it fast and intuitive for power users and beginners alike.</li> </ul> <p>Why use k9s?</p> <ul> <li>Rapidly diagnose issues, monitor workloads, and manage resources without leaving your terminal.</li> <li>Visualize pod health, events, and logs in real time.</li> <li>Reduce context switching and streamline your DevOps workflow.</li> </ul> <p>For more details, see the k9s documentation or try it out in your Codespace now.</p> <ul> <li>Let's continue</li> </ul>"},{"location":"whats-next/","title":"11. What's Next?","text":"<p>Now that you've explored the framework and best practices, you can:</p> <ul> <li>Create your own repository from the template repository and start building with the enablement framework.</li> <li>Learn from existing enablements by exploring the repositories below. Each repository demonstrates a specific use case or advanced scenario.</li> </ul>"},{"location":"whats-next/#enablement-repositories","title":"\ud83d\udcda Enablement Repositories","text":"Repository Name Description enablement-codespaces-template The main template repository to kickstart your own enablement with all framework features pre-configured. enablement-live-debugger-bug-hunting Learn live debugging and bug hunting techniques using Dynatrace in real-world scenarios. enablement-gen-ai-llm-observability Explore observability for GenAI and LLM workloads, including tracing and monitoring best practices. enablement-business-observability Focus on business analytics and observability, leveraging Dynatrace BizEvents and dashboards. enablement-dql-301 Advanced enablement for Dynatrace Query Language (DQL), including hands-on labs and exercises. enablement-dynatrace-log-ingest-101 Introduction to log ingestion and analytics with Dynatrace. enablement-kubernetes-opentelemetry Kubernetes observability and OpenTelemetry integration with Dynatrace. enablement-browser-dem-biz-observability Browser Digital Experience Monitoring and business observability use cases. enablement-workflow-essentials Essential workflows and automation for Dynatrace enablements. workshop-dynatrace-log-analytics Workshop repository for hands-on log analytics with Dynatrace. bug-busters Gamified bug hunting and troubleshooting challenges using Dynatrace. <p>Explore these repositories to deepen your knowledge or use them as a foundation for your own projects. Find the full list and latest updates in the codespaces-framework repository.</p> <p>More to come</p> <ul> <li>Stay tuned, more enablements are coming with more advanced use cases...</li> </ul>"},{"location":"snippets/admonitions/","title":"Admonitions","text":"<p>Note</p> <p>This is a Note </p> <p>Abstract</p> <p>This is an abstract</p> <p>Tipp</p> <p>This is a tipp </p> <p>Success</p> <p>This is a success </p> <p>Question</p> <p>This is a success </p> <p>Failure</p> <p>This is a failure </p> <p>Danger</p> <p>This is a danger </p> <p>Info</p> <p>This is a info</p> <p>Warning</p> <p>This is a Warning </p> <p>This is an Example admonition</p> <p>This is an example</p> This is a bug and is collapsable <p>This is a bug</p>"},{"location":"snippets/disclaimer/","title":"Disclaimer","text":"<p>Support Policy</p> <p>This is an enablement project created by the Center of Excellence - Enablement Team at Dynatrace.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"snippets/dt-enablement/","title":"Dt enablement","text":"<p>This Codespace leverages the Dynatrace Enablement Framework, providing a robust and flexible development environment. Key features include:</p> <ul> <li>Seamless operation within GitHub Codespaces, as a remote container, or locally via Docker.</li> <li>Cross-compilation support for both AMD and ARM architectures, ensuring broad compatibility.</li> <li>Adherence to industry standards and best practices to optimize the developer experience.</li> </ul> <p>To learn more about the Dynatrace Enablement Framework and how it can enhance your development workflow, please refer to the official documentation</p>"},{"location":"snippets/grail-requirements/","title":"Grail requirements","text":"<p>Requirements</p> <ul> <li>A Grail enabled Dynatrace SaaS Tenant (sign up here).</li> <li>A GitHub account to interact with the demo repository.</li> </ul>"},{"location":"snippets/view-code/","title":"View code","text":"<p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p>"}]}