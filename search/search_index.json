{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. Introduction","text":"<p>This Codespace leverages the Dynatrace Enablement Framework, providing a robust and flexible development environment. Key features include:</p> <ul> <li>Seamless operation within GitHub Codespaces, as a remote container, or locally via Docker.</li> <li>Cross-compilation support for both AMD and ARM architectures, ensuring broad compatibility.</li> <li>Adherence to industry standards and best practices to optimize the developer experience.</li> <li>Real-time observability of Kubernetes clusters using Dynatrace Full-Stack monitoring.</li> <li>Integrated Dynatrace MCP Server to deliver deep, actionable insights across distributed systems.</li> </ul> <p>To learn more about the Dynatrace Enablement Framework and how it can enhance your development workflow, please refer to the official documentation </p> <p> </p>"},{"location":"#project-goals","title":"\ud83d\udcca Project Goals","text":"Framework Objective <p>Reduce complexity, remove friction, and increase adoption of the Dynatrace Platform.</p> <p>The Dynatrace Enablement Framework is a structured set of tools and best practices designed to streamline the delivery, maintenance, and scaling of solutions across the Dynatrace Platform. The primary goal is to drive platform adoption by ensuring consistent training, comprehensive solution coverage, and operational efficiency.</p> <p>Trainings are delivered as GitHub Codespaces\u2014publicly accessible, environment-agnostic, and built to a defined set of standards for quality, repeatability, and team alignment.</p>"},{"location":"#dynatrace-enablement-framework-in-a-nutshell","title":"Dynatrace Enablement Framework in a Nutshell","text":"<p>The Dynatrace Enablement Framework simplifies the delivery of demos and hands-on trainings for the Dynatrace Platform. It provides a unified set of tools, templates, and best practices to ensure enablements are easy to create, run anywhere, and maintain over time.</p>"},{"location":"#key-features","title":"\u2705 Key Features","text":"<ul> <li> <p>GitHub-Hosted &amp; Versioned   All trainings are managed in GitHub repositories, ensuring traceability and collaboration.</p> </li> <li> <p>Self-Service Documentation   Each repo includes its own MkDocs-powered documentation, published via GitHub Pages.</p> </li> <li> <p>Universal Base Image   A Docker image supports AMD/ARM architectures, GitHub Codespaces, VS Code Dev Containers, and containerized execution in any Ubuntu OS.</p> </li> <li> <p>Separation of Concerns   Modular design allows repo-specific logic without impacting the core framework.</p> </li> <li> <p>Automated Testing   GitHub Actions enable end-to-end integration tests for all trainings.</p> </li> <li> <p>Monitoring &amp; Analytics   Usage and adoption are tracked with Dynatrace for continuous improvement.</p> </li> <li> <p>Rapid Training Creation   Templates and automation help trainers launch new enablement content quickly.</p> </li> <li> <p>Centralized Maintenance   The Codespaces Synchronizer tool keeps all repositories up to date with the latest framework changes.</p> </li> </ul>"},{"location":"#benefits","title":"\ud83e\udd32 Benefits","text":"<ul> <li>Reduces complexity and friction for trainers and learners</li> <li>Increases adoption and consistency</li> <li>Scales across internal, partner, and customer enablement a Kubernetes cluster.</li> </ul>"},{"location":"#support-policy","title":"\ud83d\udcde Support Policy","text":"<p>Support Policy</p> <p>This is an enablement project created by the Center of Excellence - Enablement Team at Dynatrace.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p> <ul> <li>Yes! let's begin </li> </ul>"},{"location":"cleanup/","title":"Cleanup","text":"<p>Deleting the codespace from inside the container</p> <p>We like to make your life easier, for convenience there is a function loaded in the shell of the Codespace for deleting the codespace, just type <code>deleteCodespace</code>. This will trigger the deletion of the codespace.</p> <p>Another way to do this is by going to https://github.com/codespaces and delete the codespace.</p> <p>You may also want to deactivate or delete the API token needed for this lab.</p> <ul> <li>Ressources</li> </ul>"},{"location":"container-image/","title":"2. Container image","text":""},{"location":"container-image/#overview","title":"Overview","text":"<p>The Dynatrace Enablement Framework leverages a custom Docker image as the foundation for all training and demo environments. This image is engineered for maximum compatibility, flexibility, and ease of use across a variety of platforms and deployment scenarios.</p>"},{"location":"container-image/#key-features","title":"Key Features","text":""},{"location":"container-image/#base-image","title":"\ud83d\uddbc\ufe0f Base Image:","text":"<p>The framework uses <code>mcr.microsoft.com/devcontainers/base:ubuntu</code> as its base image, ensuring seamless compatibility with GitHub Codespaces and Visual Studio Code Dev Containers.</p>"},{"location":"container-image/#cross-platform-support","title":"\ud83d\udcbb Cross-Platform Support:","text":"<p>The image is built to run on both AMD and ARM architectures, eliminating vendor lock-in and supporting a wide range of hardware.</p>"},{"location":"container-image/#local-and-cloud-execution","title":"\u2601\ufe0f Local and Cloud Execution:","text":"<ul> <li>Supports GitHub Codespaces for cloud-based development.</li> <li>Enables local execution on Windows, Linux, and macOS via Multipass, ensuring a consistent development environment regardless of host OS.</li> </ul>"},{"location":"container-image/#dynatrace-integration","title":"Dynatrace Integration","text":"<p>Dynatrace OneAgent FullStack and Kubernetes CloudNativeFullstack deployments are fully supported. All required components\u2014including the CSI Driver, Webhook, ActiveGate, and OneAgents\u2014can be deployed within this image, ensuring comprehensive monitoring and observability for running applications.</p>"},{"location":"container-image/#tooling","title":"Tooling","text":"<p>\ud83d\udee0\ufe0f Included tooling </p> <p>The image comes with a comprehensive set of tools required for modern DevOps and cloud-native development, including:</p> <ul> <li>Helm</li> <li>Kubectl</li> <li>Kind</li> <li>Docker</li> <li>NodeJs</li> <li>K9s</li> <li>Python</li> </ul>"},{"location":"container-image/#docker-in-socket-strategy","title":"Docker-in-Socket Strategy","text":"<p>The Dynatrace Enablement Framework uses a Docker-in-socket strategy to enable container management from within the development container. By mounting the Docker socket (<code>/var/run/docker.sock</code>) from the host into the container, the development environment can communicate directly with the host's Docker daemon.</p>"},{"location":"container-image/#how-it-works","title":"How It Works","text":"<ul> <li>The <code>entrypoint.sh</code> script inside the container manages interactions with the Docker daemon.</li> <li>By sharing the Docker socket, the container can execute Docker commands as if running directly on the host.</li> <li>This enables workflows such as building, running, and managing additional containers from within your Codespace or Dev Container.</li> </ul>"},{"location":"container-image/#benefits","title":"Benefits","text":"<ul> <li>Consistency: Docker commands behave identically inside the container and on the host.</li> <li>Flexibility: Supports advanced scenarios such as running nested containers or orchestrating multi-container setups.</li> <li>Simplicity: No need to install Docker inside the container; it leverages the host\u2019s Docker installation.</li> </ul>"},{"location":"container-image/#example","title":"Example","text":"<p>In the <code>devcontainer.json</code>, mount the Docker socket as follows:</p> <pre><code>\"mounts\": [\"source=/var/run/docker.sock,target=/var/run/docker.sock,type=bind\"]\n</code></pre>"},{"location":"container-image/#special-container-runtime-arguments","title":"Special Container Runtime Arguments","text":"<p>The following <code>runArgs</code> configuration in <code>devcontainer.json</code> enhances the capabilities of the development container:</p> <pre><code>\"runArgs\": [\"--init\", \"--privileged\", \"--network=host\"]\n</code></pre> <ul> <li>--init: Runs an init process inside the container to handle zombie processes and signal forwarding, improving container stability.</li> <li>--privileged: Grants the container extended privileges, allowing access to all host devices and enabling operations typically restricted in standard containers. This is useful for scenarios requiring low-level system access (e.g., running Docker inside Docker or accessing host resources).</li> <li>--network=host: Shares the host\u2019s networking stack with the container, enabling direct use of the host\u2019s network interfaces. This is helpful for networking tests or when services inside the container need to be accessible on the host network.</li> </ul>"},{"location":"container-image/#image-distribution","title":"Image Distribution","text":"<p>The image is hosted on Docker Hub and is cross-compiled for ARM and AMD architectures. </p>"},{"location":"container-image/#using-the-image-in-devcontainerjson","title":"Using the Image in devcontainer.json","text":"<p>You can configure your development container to use the pre-built image or build it yourself from a Dockerfile, depending on your requirements.</p>"},{"location":"container-image/#using-the-pre-built-image","title":"Using the Pre-built Image","text":"<p>To use the pre-built image, specify the \"image\" property in your devcontainer.json file:</p> <p><pre><code>  // Pulling the image from the Dockerhub, runs on AMD64 and ARM64. Pulling is normally faster.\n  \"image\":\"shinojosa/dt-enablement:v1.1\",\n</code></pre> This will pull the published image from Docker Hub and use it as the base for your Codespace or Dev Container.</p>"},{"location":"container-image/#building-the-image-with-vs-code","title":"Building the Image with VS Code","text":"<p>If you want to build the image yourself (for example, to customise it), you need to use the \"build\" section in your devcontainer.json. Uncomment or add the following: <pre><code>  // \"image\": \"shinojosa/dt-enablement\",  \n  \"build\": {    \n    \"dockerfile\": \"Dockerfile\"  }\n    },\n</code></pre></p> <p>Comment out or remove the \"image\" line. Uncomment or add the \"build\" section, pointing to your Dockerfile. This will instruct the environment to build the image locally using your Dockerfile.</p>"},{"location":"container-image/#cross-compiling-with-buildx","title":"Cross-Compiling with Buildx","text":"<p>In the <code>.devcontainer</code> folder, there is a <code>Makefile</code> that includes a <code>buildx</code> target specifically designed for cross-compiling the container image.</p> <p>To use cross-compilation:</p> <ul> <li>Make sure your host architecture is ARM.</li> <li>Run the <code>buildx</code> target from the <code>Makefile</code> to build the image for multiple architectures.</li> </ul> <p>Example usage:</p> CrossCompiling target<pre><code>make buildx\n</code></pre> <ul> <li>Let's continue</li> </ul>"},{"location":"dynatrace-integration/","title":"4. Dynatrace integration","text":"<p>This section explains how Dynatrace monitors applications and integrates with the Dynatrace MCP Server.</p> <p>\ud83d\udea7 Section is under construction</p> <p>This section is a work in progress and will be updated shortly with the instructions on how to enable the MCP Server in any enablement... </p>"},{"location":"dynatrace-integration/#mcp-server-integration","title":"MCP Server Integration","text":"<p>The Dynatrace MCP Server acts as a central hub for managing and analyzing monitoring data, enabling seamless integration with your applications.</p>"},{"location":"dynatrace-integration/#application-monitoring","title":"Application Monitoring","text":"<p>Dynatrace provides real-time monitoring of your applications, offering insights into performance, errors, and user behavior.</p> <ul> <li>Let's continue</li> </ul>"},{"location":"enablements/","title":"12. Enablements","text":"<p>Explore these repositories to deepen your knowledge or use them as a foundation for your own projects.  </p>"},{"location":"enablements/#enablement-repositories","title":"\ud83d\udcda Enablement Repositories","text":"Repository Name Description enablement-codespaces-template The main template repository to kickstart your own enablement with all framework features pre-configured. enablement-live-debugger-bug-hunting Learn live debugging and bug hunting techniques using Dynatrace in real-world scenarios. enablement-gen-ai-llm-observability Explore observability for GenAI and LLM workloads, including tracing and monitoring best practices. enablement-business-observability Focus on business analytics and observability, leveraging Dynatrace BizEvents and dashboards. enablement-dql-301 Advanced enablement for Dynatrace Query Language (DQL), including hands-on labs and exercises. enablement-dynatrace-log-ingest-101 Introduction to log ingestion and analytics with Dynatrace. enablement-kubernetes-opentelemetry Kubernetes observability and OpenTelemetry integration with Dynatrace. enablement-browser-dem-biz-observability Browser Digital Experience Monitoring and business observability use cases. enablement-workflow-essentials Essential workflows and automation for Dynatrace enablements. workshop-dynatrace-log-analytics Workshop repository for hands-on log analytics with Dynatrace. bug-busters Gamified bug hunting and troubleshooting challenges using Dynatrace. <p>More to come</p> <ul> <li>Stay tuned, more enablements are coming with more advanced use cases...</li> </ul> <ul> <li>Continue to What's Next \u2192</li> </ul>"},{"location":"framework/","title":"6. The Framework","text":"<p> This section outlines the structure and purpose of each component in the Codespaces Enablement Framework, as visualized in the architecture diagram.</p>"},{"location":"framework/#container-configuration-for-vs-code","title":"\ud83d\udfe6 Container Configuration for VS Code","text":"<p>Defines the development container for VS Code and Codespaces. Extensions are kept minimal to ensure portability across platforms (ARM and AMD), allowing the environment to run in plain Docker or on different architectures.</p> <ul> <li>Dockerfile: Specifies the base image and all required tools/libraries.</li> <li>devcontainer.json: Main configuration file for the development container. It defines settings, installed extensions, mounted volumes, arguments, environment variables, and how VS Code should start and connect to the container.</li> </ul>"},{"location":"framework/#documentation-workflow-docs","title":"\ud83d\udfe9 Documentation Workflow (<code>docs/</code>)","text":"<ul> <li>docs/: Contains all documentation and site configuration.</li> <li>mkdocs.yaml: Defines navigation and site structure for MkDocs.</li> <li>.github/workflows/deploy-ghpages.yaml: GitHub Actions workflow to deploy documentation to GitHub Pages when a PR is merged into main.</li> </ul>"},{"location":"framework/#live-documentation","title":"Live Documentation","text":"<ul> <li>installMkdocs: Installs all requirements for MkDocs (including Python dependencies from <code>docs/requirements/requirements-mkdocs.txt</code>) and exposes the documentation locally. This is the recommended way to set up the documentation server in your dev container.</li> <li>exposeMkdocs: Launches the MkDocs development server on port 8000 inside your dev container, making the documentation available for live preview with live reload. This function is called by installMkdocs.</li> </ul>"},{"location":"framework/#deploying-to-github-pages","title":"Deploying to GitHub Pages","text":"<ul> <li>deployGhdocs: Builds and deploys the documentation to GitHub Pages using <code>mkdocs gh-deploy</code>, publishing your latest docs to the configured GitHub Pages site.</li> </ul>"},{"location":"framework/#app-repository-apps","title":"\ud83d\udfe8 App Repository (<code>apps/</code>)","text":"<p>This directory contains the application code and sample apps to be included in the enablement. Each app should have its own subfolder inside <code>apps/</code>.</p>"},{"location":"framework/#port-allocation-and-nodeport-strategy","title":"Port Allocation and NodePort Strategy","text":"<p>When deploying applications, the framework automatically allocates the ports exposed by the Kind Kubernetes cluster using the NodePort strategy. The <code>getNextFreeAppPort</code> function is called before deploying each app to select an available port from the defined range. By default, three ports are used, as defined in the <code>PORTS</code> variable in <code>.devcontainer/util/variables.sh</code>:</p> <pre><code>PORTS=(\"30100\" \"30200\" \"30300\")\n</code></pre> <p>These ports are mapped to your applications, making them accessible from your host machine. The NodePort strategy ensures each app can be reached via a unique port on the cluster node.</p>"},{"location":"framework/#managing-apps-with-deployapps","title":"Managing Apps with <code>deployApps</code>","text":"<p>The framework provides a <code>deployApps</code> function to help you deploy and undeploy the applications listed in the <code>apps/</code> directory to your Kubernetes cluster.</p> <p>Running <code>deployApps</code> without parameters displays an interactive help menu listing all available apps, their aliases, and their compatibility (AMD/ARM). Example output:</p> <p> </p>"},{"location":"framework/#to-deploy-an-app","title":"To deploy an app","text":"<ul> <li>Use any of the listed numbers, characters, or names. For example, to deploy <code>astroshop</code>, you can run:     <pre><code>deployApps 2\n# or\ndeployApps b\n# or\ndeployApps astroshop\n</code></pre></li> </ul>"},{"location":"framework/#to-undeploy-an-app","title":"To undeploy an app","text":"<ul> <li>Add <code>-d</code> as an extra argument:     <pre><code>deployApps 2 -d\n# or\ndeployApps astroshop -d \n</code></pre></li> </ul> <p>Each app folder should contain its own deployment and cleanup scripts or instructions. The <code>deployApps</code> function will call these as needed.</p>"},{"location":"framework/#running-locally","title":"\ud83d\udfe7 Running Locally","text":"<p>To quickly start a local development container, run:</p> <pre><code>cd .devcontainer\nmake start\n</code></pre> <p>Scripts and configuration for building and running the environment outside Codespaces include:</p> <ul> <li>Makefile: Main entrypoint for local development (<code>make start</code>). It defines targets for starting, stopping, and managing the local container environment.</li> <li> <p>makefile.sh: Contains the core Bash logic for building, running, and managing the container. The Makefile sources this script to execute its targets. Key responsibilities include:</p> <ul> <li>Building the Docker image if it does not exist</li> <li>Starting the container with the correct environment, ports, and volumes</li> <li>Attaching to a running container or recreating it if stopped</li> <li>Handling cleanup and removal of containers/images</li> <li>Providing utility functions for logs, shell access, and status checks</li> </ul> <p>This separation allows you to keep complex logic in Bash, while the Makefile provides a simple interface for users.</p> </li> <li> <p>runlocal/: Local environment configuration, including:</p> <ul> <li><code>.env</code>: Secrets and environment variables for local runs.</li> <li><code>helper.sh</code>: Helper scripts for local setup.</li> </ul> </li> </ul>"},{"location":"framework/#github-actions-integration-tests","title":"\ud83d\udfea GitHub Actions &amp; Integration Tests","text":"<p>Automation for CI/CD and integration testing: - .github/workflows/integration-tests.yaml: Workflow for running integration tests on every Pull Request (PR) and push. The <code>main</code> branch is protected: integration tests must pass for any PR before it can be merged into <code>main</code>. - test/: Contains test scripts:     - <code>integration.sh</code>: Main integration test runner.     - <code>test_functions.sh</code>: Test utilities and functions.</p>"},{"location":"framework/#integration-test-function","title":"Integration Test Function","text":"<ul> <li>runIntegrationTests: This function triggers the integration tests for the repository by running the <code>integration.sh</code> script. It is used both locally and by the CI pipeline to ensure the environment and applications work as expected before merging changes.</li> </ul> integration.sh<pre><code>#!/bin/bash\n# Load framework\nsource .devcontainer/util/source_framework.sh\n\nprintInfoSection \"Running integration Tests for $RepositoryName\"\n\nassertRunningPod dynatrace operator\n\nassertRunningPod dynatrace activegate\n\nassertRunningPod dynatrace oneagent\n\nassertRunningPod todoapp todoapp\n\nassertRunningApp 30100\n</code></pre> <p>These assertions check that the required pods (operator, activegate, oneagent, and todoapp) are running in their respective namespaces, and that the application is accessible on the expected port (30100). If any assertion fails, the integration test will fail and block the PR from being merged.</p>"},{"location":"framework/#kubernetes-cluster","title":"\ud83d\udfeb Kubernetes Cluster","text":"<p>The Kubernetes cluster for the enablement is defined in the <code>kind-cluster.yaml</code> file. This configuration is used by Kind (Kubernetes IN Docker) to spin up a local Kubernetes cluster as a Docker container, using the Docker-in-socket strategy. The enablement container attaches to the Kind cluster, allowing you to deploy and test applications in a real Kubernetes environment.</p>"},{"location":"framework/#managing-the-kind-cluster","title":"Managing the Kind Cluster","text":"<p>The following functions are provided to manage the lifecycle of the Kind cluster:</p> <ul> <li>startKindCluster: Starts the Kind cluster. If a cluster is already running, it attaches to it; if stopped, it starts it; if none exists, it creates a new one.</li> <li>attachKindCluster: Attaches your environment to a running Kind cluster by configuring your kubeconfig for access.</li> <li>createKindCluster: Creates a new Kind cluster using the configuration in <code>kind-cluster.yaml</code>.</li> <li>stopKindCluster: Stops the Kind cluster Docker container.</li> <li>deleteKindCluster: Deletes the Kind cluster and removes all associated resources.</li> </ul> <p>These functions allow you to easily start, stop, attach, create, or delete your local Kubernetes cluster for development and testing.</p> <p>The <code>kubectl</code> client, <code>helm</code>, and <code>k9s</code> are automatically configured to work with the Kind cluster, so you can manage and observe your Kubernetes resources out of the box.</p>"},{"location":"framework/#docker-socket-mapping-entrypointsh","title":"\ud83d\udc33 Docker Socket Mapping (<code>entrypoint.sh</code>)","text":"<p>This section enables the container to access the host's Docker daemon by mounting the Docker socket (<code>/var/run/docker.sock</code>). This allows the container to start and manage sibling containers, which is essential for running Kind and other Docker-based tools inside the dev environment.</p> <p>entrypoint.sh: This script is executed when the container starts. It sets up the environment, ensures the Docker socket is available, and configures any required permissions or environment variables so that Docker commands work seamlessly inside the container.</p>"},{"location":"framework/#container-post-creation-start-post-createsh-post-startsh","title":"\ud83d\udfe6 Container Post-Creation &amp; Start (<code>post-create.sh</code>, <code>post-start.sh</code>)","text":"<p>Repository-Specific Logic</p> <p>Use these files to define logic for automating the creation and setup of your enablement.</p> <p>These scripts automate the setup and initialization of your development container:</p> <ul> <li> <p>post-create.sh: Runs after the Codespace or dev container is created. It loads all framework and custom functions into the shell, then executes a series of setup steps in order:</p> <p>Example <code>post-create.sh</code>: .devcontainer/post-create.sh<pre><code>#!/bin/bash\n# Load functions\nexport SECONDS=0\nsource .devcontainer/util/source_framework.sh\n\nsetUpTerminal\n\nstartKindCluster\n\ninstallK9s\n\ndynatraceDeployOperator\n\ndeployCloudNative\n\ndeployTodoApp\n\nfinalizePostCreation\n\nprintInfoSection \"Your dev container finished creating\"\n</code></pre></p> </li> <li> <p>post-start.sh: Runs every time the container starts (e.g., refresh tokens, check dependencies, interact with the user).</p> </li> </ul>"},{"location":"framework/#core-functions-util","title":"\ud83d\udfe5 Core Functions (<code>util/</code>)","text":"<p>This directory contains reusable shell functions, variables, and logic that power the framework. These scripts are loaded into every shell session, making their utilities available for all automation and interactive tasks.</p> <ul> <li>functions.sh: Main library of core functions for the framework. Includes:<ul> <li>Logging and info utilities (<code>printInfo</code>, <code>printWarn</code>, <code>printError</code>, <code>printInfoSection</code>)</li> <li>Kubernetes helpers (e.g., <code>waitForPod</code>, <code>waitForAllPods</code>, <code>waitForAllReadyPods</code>)</li> <li>Application deployment, integration, and environment management functions</li> <li>Functions for tracking codespace creation, printing greetings, and more</li> <li>All functions are loaded dynamically for use in the shell or scripts</li> </ul> </li> <li>source_framework.sh: Loads the framework and all utility scripts into the shell, ensuring both core and custom functions are available in every environment (Codespaces, VS Code, or plain Docker).</li> <li>greeting.sh: Displays a welcome message and branding when a new shell session starts, including useful environment info and quickstart tips. Print the greeting at any time by calling the <code>printGreeting</code> function or by opening a new zsh terminal.</li> <li>variables.sh: Central place for defining and exporting all default variables, such as image versions, port ranges, and environment-specific settings. This ensures consistency and easy configuration across the framework.</li> </ul>"},{"location":"framework/#custom-functions","title":"\ud83d\udfeb Custom Functions","text":"<ul> <li>my_functions.sh: Define repository-specific or custom functions here. This file is loaded after the core framework, allowing you to override or extend any behavior. For example, add a function to deploy your own app and call it from <code>post-create.sh</code>.</li> </ul>"},{"location":"framework/#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the Apache 2.0 License.</p> <ul> <li>Let's continue</li> </ul>"},{"location":"instantiation-types/","title":"3. Instantiation types","text":"<p>Choose the option that best fits your needs! \ud83d\ude80</p> <p>The Dynatrace Enablement Framework supports multiple ways to instantiate your development environment. You can run it in Github Codespaces, VS Code Dev Containers or local containers, in AMD or ARM architectures.  </p>"},{"location":"instantiation-types/#quick-step-by-step-guide-instantiating-your-environment","title":"\ud83c\udfc3\ud83c\udffb\u200d\u2642\ufe0f Quick Step by Step guide: Instantiating Your Environment","text":""},{"location":"instantiation-types/#1-running-in-github-codespaces","title":"1. Running in GitHub Codespaces","text":"<ol> <li>Go to the repository hosted on GitHub.</li> <li>Click the &lt;&gt; Code button.</li> <li>Create a new Codespace using the main branch, or click + New to customize how and where to run the Codespace within GitHub Cloud.</li> </ol> <p>Repository secrets such as <code>DT_ENVIRONMENT</code>, <code>DT_OPERATOR_TOKEN</code>, and <code>DT_INGEST_TOKEN</code> (among others) are injected automatically using GitHub Codespaces secrets. No manual setup is required\u2014these are available as environment variables inside the container.</p>"},{"location":"instantiation-types/#2-running-in-vs-code-dev-containers-or-local-container","title":"2.  \ud83d\udce6 Running in VS Code Dev Containers or Local Container","text":"Key Difference: VS Code Dev Container vs Local Container <p>The main difference between a VS Code Dev Container and a local container is how each environment is created and managed. A VS Code Dev Container is launched and orchestrated by VS Code using the configuration in <code>devcontainer.json</code>. A local container is started independently using the Makefile and <code>runlocal</code> script, allowing you to build and manage the container from the terminal without relying on VS Code. This is ideal for headless or automated workflows.</p> <p>The following steps apply to both scenarios:</p> <ol> <li> <p>Provision Infrastructure</p> \ud83c\udfd7\ufe0f Setting up the Infrastructure <p>You may provision your infrastructure on any major cloud provider or run locally using Multipass.</p> <p>Minimum requirements for a cloud or local machine: 1. Operating System: Ubuntu LTS (22.04 or 24.04 recommended) 2. CPU &amp; Memory: Requirements depend on your workloads. As a guideline, refer to the <code>hostRequirements</code> section in <code>.devcontainer.json</code>. A typical setup with 4 CPU cores and 16 GB RAM is sufficient for most use cases. 3. Network Ports: Ensure the following ports are open for inbound connections:     - <code>22</code> (SSH)     - <code>30100</code>, <code>30200</code>, <code>30300</code> (for application access; each deployed app is exposed via Kubernetes NodePort)</p> </li> <li> <p>SSH into the host</p> </li> <li> <p>Clone the repository</p> </li> <li> <p>Set up secrets and environment variables</p> <ul> <li>Define all required secrets as environment variables. For both VS Code Dev Containers and local containers, create a <code>.env</code> file under <code>.devcontainer/runlocal/.env</code>.</li> <li>The secrets required are defined in the <code>secrets</code> section of <code>.devcontainer.json</code>. If no secrets are needed, create an empty <code>.env</code> file.</li> </ul> Sample <code>.env</code> file <p>You can copy and paste the following sample into <code>.devcontainer/runlocal/.env</code>. Ensure all required secrets for the training are included.</p> .devcontainer/runlocal/.env<pre><code># Environment variables as defined as secrets in the devcontainer.json file\n# Dynatrace Tenant\nDT_ENVIRONMENT=https://abc123.apps.dynatrace.com\n\n# Dynatrace Operator Token\nDT_OPERATOR_TOKEN=dt0c01.XXXXXX\n\n# Dynatrace Ingest Token\nDT_INGEST_TOKEN=dt0c01.YYYYYY\n\n# Add any other environment variables as needed\n</code></pre> </li> <li> <p>Verify prerequisites</p> <ul> <li>Ensure <code>make</code> and <code>docker</code> are installed on the host and the user has access to Docker.</li> </ul> Verify prerequisites with <code>checkHost</code> <p>Use the provided function to verify requirements. If any are missing, the function offers to install them for you. <pre><code>source .devcontainer/util/source_framework.sh &amp;&amp; checkHost\n</code></pre> </p> </li> </ol> <p>Ready to Launch</p> <p>You are all set! Launch the enablement with VS Code as a dev container or with <code>make</code> as a plain Docker container.</p>"},{"location":"instantiation-types/#2-a-running-as-dev-container-with-vs-code","title":"2. a. \ud83d\udce6 \ud83d\udda5\ufe0f Running as dev container with VS Code","text":"<ol> <li>Let's tell VS Code to read the secrets as environment variables from an <code>.env</code>file. Modify the <code>runArgs</code> in <code>.devcontainer/devcontainer.json</code> and add <code>\"--env-file\", \".devcontainer/runlocal/.env\"</code>like the following:     <pre><code>\"runArgs\": [\"--init\", \"--privileged\", \"--network=host\", \"--env-file\", \".devcontainer/runlocal/.env\"]\n</code></pre></li> <li>This ensures all variables in <code>.devcontainer/runlocal/.env</code> are available inside the container.</li> <li>Open the folder in VS Code and use the Dev Containers extension to \"Reopen in Container\". VS Code will use the <code>.devcontainer/devcontainer.json</code> definition to build and start the environment for you.</li> <li>You can rebuild the container at any time by typing <code>[CTRL] + Shift P &gt; Dev Containers: Rebuild and reopen in container</code></li> </ol>"},{"location":"instantiation-types/#2-b-running-as-local-container-with-make","title":"2. b. \ud83d\udce6 \ud83d\udc33 Running as local container with make","text":"<ol> <li>Navigate to <code>.devcontainer</code> folder and run:     <pre><code>make start\n</code></pre></li> <li> <p>This will build and launch the container. All ports, volumes, and environment variables are set up automatically.</p> <p>Protip: create a new Terminal</p> <p>For attaching a new Terminal to the container, just type <code>make start</code>.</p> </li> <li> <p>Secrets and environment variables are loaded from <code>.devcontainer/runlocal/.env</code>. </p> </li> <li>The <code>makefile.sh</code> script passes the variables to Docker at runtime such as arguments, volume mounts and port-forwarding. The devcontainer.json file is not used with this set-up.</li> </ol>"},{"location":"instantiation-types/#instantiation-types","title":"Instantiation Types","text":""},{"location":"instantiation-types/#1-github-codespaces","title":"1. \u2601\ufe0f GitHub Codespaces","text":"<ul> <li>One-click cloud dev environments </li> <li>No local setup required\u2014just click  </li> <li>Learn more about Codespaces</li> </ul>"},{"location":"instantiation-types/#2-vs-code-dev-containers","title":"2. \ud83d\udda5\ufe0f VS Code Dev Containers","text":"<ul> <li>Use the Dev Containers extension for a seamless local experience in VS Code</li> <li>All configuration is in <code>.devcontainer/devcontainer.json</code></li> <li>Supports secrets, port forwarding, and post-create hooks</li> </ul>"},{"location":"instantiation-types/#3-local-container","title":"3. \ud83d\udc33 Local Container","text":"<ul> <li>Run the same environment on your machine using Docker.</li> <li>Easiest way: just run <code>make start</code> in the <code>.devcontainer</code> folder.</li> <li>This will build and launch the container if needed, or attach to it if already running.</li> <li>All ports, volumes, and environment variables are set up for you automatically.</li> </ul>"},{"location":"instantiation-types/#quick-comparison","title":"\u26a1 Quick Comparison","text":"Type Runs On VS Code Needed Fast Start Customizable Secrets Handling Port Forwarding Best For \u2601\ufe0f Codespaces GitHub Cloud \u274c \u2705 \u274c Auto-injected Auto Quick onboarding, demos \ud83d\udda5\ufe0f VS Code DevContainer Provided Infrastructure \u2705 \u2705 \u2705 Auto/manual Auto Full-featured local dev \ud83d\udc33 Local Container Provided Infrastructure \u274c \u2705 \u2705 Manual/<code>.env</code> Manual/Makefile Reproducible local dev"},{"location":"instantiation-types/#secrets-environment","title":"\ud83d\udd10 Secrets &amp; Environment","text":"<p>Secrets and environment variables are handled differently depending on the instantiation type:</p> Instantiation Type How Secrets Are Provided Where to Configure/Set Notes \u2601\ufe0f Codespaces Auto-injected as environment variables from GitHub Codespaces secrets GitHub repository &gt; Codespaces secrets No manual setup; secrets available at container start \ud83d\udda5\ufe0f VS Code Dev Containers Passed as environment variables via <code>runArgs</code> and <code>.env</code> file <code>.devcontainer/devcontainer.json</code>, <code>.devcontainer/runlocal/.env</code> Edit/add <code>.devcontainer/runlocal/.env</code> for local secrets; <code>runArgs</code> must include <code>--env-file</code> \ud83d\udc33 Local Container Loaded from <code>.devcontainer/runlocal/.env</code> file and passed to Docker at runtime by <code>makefile.sh</code> <code>.devcontainer/runlocal/.env</code>, <code>makefile.sh</code> Run <code>make start</code> in <code>.devcontainer</code>; secrets loaded at container start"},{"location":"instantiation-types/#running-locally","title":"\ud83c\udfe0 Running locally","text":""},{"location":"instantiation-types/#using-multipass-for-local-development","title":"Using Multipass for Local Development","text":"<p>Multipass is a lightweight VM manager from Canonical that makes it easy to launch and manage Ubuntu virtual machines on macOS, Windows, and Linux. This is especially useful if you want to run the framework in a clean, reproducible Ubuntu environment without dual-booting or using a full desktop VM.</p> <p>Why use Multipass?</p> <ul> <li>Ensures compatibility with Ubuntu-based dev containers and scripts</li> <li>Isolates your development environment from your host OS</li> <li>Quick to launch, easy to reset or remove</li> </ul>"},{"location":"instantiation-types/#basic-usage","title":"Basic usage","text":"<ul> <li>Install Multipass (instructions) </li> <li>Launch an Ubuntu VM: <pre><code>multipass launch --name enablement --disk 30G --cpus 8 --memory 32G\nmultipass shell enablement\n</code></pre></li> </ul> <p>Mounting Volumes on Multipass</p> <p>You can mount folders from your host into the VM using <code>multipass mount</code> if you want to edit code locally but run containers in the VM. For example in the following example we are creating a VM mounting the folder <code>enablement</code> where you have all repositories of the enablement framework you want to use.  <pre><code>multipass launch --name enablement --disk 30G --cpus 8 --memory 32G --mount  /Users/sergio.hinojosa/repos/enablement:/home/ubuntu/enablement\n</code></pre></p> <ul> <li>Let's continue</li> </ul>"},{"location":"monitoring/","title":"10. Monitoring","text":"<p>Monitoring is a critical aspect of maintaining quality, reliability, and visibility across all repositories and their instantiations in the enablement framework. By tracking usage and interactions, we ensure every codespace and its associated resources operate as expected and deliver value.</p>"},{"location":"monitoring/#why-monitoring-matters","title":"\ud83d\udce1 Why Monitoring Matters","text":"<ul> <li>Visibility: Gain insights into how repositories and codespaces are used and adopted.</li> <li>Quality Assurance: Detect issues early and ensure all deployments meet expected standards.</li> <li>Business Insights: Understand usage patterns and derive business value from operational data.</li> <li>Showcase Best Practices: Demonstrate the power of Dynatrace by monitoring our own codespaces (\u201cDrink your own Champagne\u201d principle).</li> </ul>"},{"location":"monitoring/#monitoring-approach","title":"Monitoring Approach","text":"<ul> <li> <p>GitHub Pages &amp; Agentless RUM:   Every codespace is associated with a GitHub Page. For each GitHub Page, an agentless Real User Monitoring (RUM) application is created, enabling end-to-end visibility into user interactions and performance.</p> </li> <li> <p>Automated Tracking on Creation:   When a new codespace is instantiated, the <code>finalizePostCreation</code> function sends a JSON payload to codespaces-tracker.whydevslovedynatrace.com/api/receive.  </p> </li> <li>Only requests with the correct authentication header are accepted.</li> <li> <p>This payload contains metadata about the codespace, its repository, and its usage context.</p> </li> <li> <p>Codespaces-Tracker Service:   The Codespaces-Tracker is a Spring Boot application deployed on a GKE (Google Kubernetes Engine) cluster with three replicas for high availability.</p> </li> <li>It processes incoming payloads, enriches them with geo-information, and logs the JSON payload.</li> <li>The monitoring OneAgent generates BizEvents from the pod logs, enabling advanced business-related log use cases and analytics.</li> </ul>"},{"location":"monitoring/#benefits","title":"Benefits","text":"<ul> <li>Comprehensive Monitoring:   All codespaces and their GitHub Pages are monitored for activity, performance, and adoption.</li> <li>Enhanced Observability:   Real-time data collection and enrichment provide actionable insights for both technical and business stakeholders.</li> <li>Demonstration of Dynatrace Capabilities:   By monitoring our own codespaces, we showcase Dynatrace\u2019s observability features in real-world scenarios.</li> </ul>"},{"location":"monitoring/#implementation","title":"Implementation","text":""},{"location":"monitoring/#codespaces-instantiations","title":"\ud83c\udf0e Codespaces Instantiations","text":"<p>All codespace instantiations are monitored by sending a signal to the Codespaces-Tracker service running in the GKE cluster. This is achieved through the <code>verifyCodespaceCreation</code> function, which validates the successful creation of a codespace. </p> <ul> <li>verifyCodespaceCreation:   Checks that the codespace environment has been set up correctly and all required components are running. Once verification is complete, it calls the <code>postCodespaceTracker</code> function.</li> <li>postCodespaceTracker:   Sends a JSON payload containing metadata about the codespace (such as repository name, user, and environment details) to the Codespaces-Tracker API endpoint. The payload is authenticated and enriched with geo-information, and BizEvents are generated from the logs for further analysis.</li> </ul>"},{"location":"monitoring/#github-pages","title":"\ud83d\udcca GitHub Pages","text":"<p>GitHub Pages are monitored using Dynatrace Agentless Real User Monitoring (RUM):</p> <ul> <li>An agentless RUM snippet is injected into the <code>main.html</code> template located in the <code>overrides</code> folder. This ensures every page load is tracked for user interactions and performance metrics.</li> <li>Additionally, each markdown page includes a JavaScript snippet at the top that sends a BizEvent with the name of the page to Dynatrace. This allows for detailed tracking of user navigation and engagement across the documentation.</li> </ul>"},{"location":"monitoring/#learn-more","title":"Learn More","text":"<ul> <li>Dynatrace Agentless RUM Documentation</li> <li>Business Events with Dynatrace</li> </ul> <ul> <li>Continue to Resources \u2192</li> </ul>"},{"location":"resources/","title":"11. Resources","text":"<p>Below is a curated list of resources to help you get the most out of Dynatrace, Codespaces, and modern development best practices. These links will deepen your understanding and keep you up to date with the latest trends.</p>"},{"location":"resources/#get-started-with-dynatrace","title":"\ud83d\ude80 Get Started with Dynatrace","text":"<ul> <li>Create a Free Trial in Dynatrace</li> <li>Dynatrace Documentation</li> </ul>"},{"location":"resources/#dynatrace-news-community","title":"\ud83d\udcf0 Dynatrace News &amp; Community","text":"<ul> <li>Dynatrace Blog</li> <li>Dynatrace Community</li> </ul>"},{"location":"resources/#coding-best-practices","title":"\ud83d\udca1 Coding Best Practices","text":"<ul> <li>Coding Best Practices (Dynatrace Docs)</li> <li>Separation of Concerns (Wikipedia)</li> <li>GitHub Flow: Simple Git Branching Model</li> </ul>"},{"location":"resources/#git-strategies-collaboration","title":"\ud83d\udee0\ufe0f Git Strategies &amp; Collaboration","text":"<ul> <li>Git Strategies and Workflows</li> <li>Pull Requests and Code Reviews</li> </ul>"},{"location":"resources/#containerization-cloud-native-principles","title":"\ud83c\udfd7\ufe0f Containerization &amp; Cloud-Native Principles","text":"<ul> <li>Container Design Principles (Docker)</li> <li>Kubernetes Basics</li> <li>Why Codespaces? (GitHub Docs)</li> </ul>"},{"location":"resources/#enhancing-user-experience","title":"\ud83c\udfa8 Enhancing User Experience","text":"<ul> <li>User Experience Best Practices (NNG)</li> <li>Agentless Real User Monitoring (Dynatrace)</li> </ul>"},{"location":"resources/#observability-business-insights","title":"\ud83d\udcc8 Observability &amp; Business Insights","text":"<ul> <li>Business Events in Dynatrace</li> <li>Observability Explained (Dynatrace Blog)</li> </ul> <p>Explore these resources to become more effective with Dynatrace, Codespaces, and modern software engineering.</p> <ul> <li>Continue to Enablements \u2192</li> </ul>"},{"location":"synchronizer/","title":"8. Synchronizer","text":"<p>Codespaces Synchronizer \ud83d\udd01</p> <p>Maintaining and updating multiple repositories can be complex and time-consuming. The codespaces-synchronizer is designed to keep all repositories using the framework up to date with minimal manual intervention. </p>"},{"location":"synchronizer/#overview","title":"Overview","text":"<p>The synchronizer runs from a host machine where all target repositories are cloned. It uses Bash scripting and <code>rsync</code> to automate repository management tasks, including updates, migrations, tagging, and branch protection. The synchronizer consists of two main files:</p> <ul> <li><code>synch_functions.sh</code>: Contains all core logic and reusable functions for repository operations.</li> <li><code>run.sh</code>: Entry point script that loads the framework and orchestrates the synchronization process by invoking functions from <code>synch_functions.sh</code>.</li> </ul>"},{"location":"synchronizer/#key-use-cases","title":"Key Use Cases","text":"<ul> <li>Update repositories: Propagate framework or configuration changes across multiple repositories.</li> <li>Migrate repositories: Move or refactor repositories while preserving history and structure.</li> <li>Create tags, versions, and releases: Automate versioning and release management.</li> <li>Protect branches and test workflows: Enforce branch protection rules and validate workflows.</li> </ul>"},{"location":"synchronizer/#requirements","title":"Requirements","text":"<ul> <li>A host machine with all target repositories cloned locally</li> <li>GitHub permissions to create branches and pull requests</li> <li>Bash terminal access</li> <li><code>rsync</code> installed on the host</li> </ul>"},{"location":"synchronizer/#strategies-for-updating-and-migrating-repositories","title":"Strategies for Updating and Migrating Repositories","text":"<ul> <li>Cherry-pick: Selectively apply commits from the synchronizer remote repository.</li> <li>Rsync: Efficiently synchronize files and directories between repositories (preferred approach).</li> </ul>"},{"location":"synchronizer/#how-it-works","title":"How It Works","text":"<ol> <li>Initialization: <code>run.sh</code> sets up environment variables and loads <code>synch_functions.sh</code>.</li> <li>Repository selection: The synchronizer can operate on all repositories or a specified subset.</li> <li>Function execution: Core functions (such as updating files, creating tags, or migrating content) are executed in batch across repositories.</li> <li>Automation: Common git operations (checkout, pull, commit, push, PR creation, verify PR, merge PR) are automated, reducing manual effort and risk of errors.</li> </ol> <ul> <li>Continue to Testing \u2192</li> </ul>"},{"location":"template/","title":"5. Codespaces Template","text":"<p>The Enablement Codespaces Template</p> <p> The Enablement Codespaces Template is a ready-to-use GitHub repository designed to help you create, customize, and deliver hands-on enablements using GitHub Codespaces. It provides a robust starting point for trainers, solution architects, and educators to build interactive learning environments with minimal setup.</p>"},{"location":"template/#what-is-the-codespaces-template","title":"\ud83d\ude80 What is the Codespaces Template?","text":"<p>This template repository offers:</p> <ul> <li>A pre-configured <code>.devcontainer</code> for instant Codespaces launches</li> <li>Example documentation and structure for enablement content</li> <li>GitHub Actions for CI/CD and documentation deployment</li> <li>Integration with Dynatrace and other cloud-native tools</li> <li>A clean starting point for your own enablement projects</li> </ul>"},{"location":"template/#repository-overview","title":"\ud83d\udce6 Repository Overview","text":"<p>Main features:</p> <ul> <li>.devcontainer/: All configuration for Codespaces and local dev containers</li> <li>docs/: MkDocs-based documentation, ready to extend</li> <li>.github/workflows/: CI/CD for integration tests and GitHub Pages deployment</li> <li>README.md: Project overview and quickstart</li> <li>mkdocs.yaml: Navigation and site configuration</li> </ul> <p>For a complete file and folder breakdown, see the repository on GitHub.</p>"},{"location":"template/#how-to-use-the-template","title":"\ud83d\udcdd How to Use the Template","text":"<ol> <li>Create your own enablement repository<ul> <li>Click \"Use this template\" on the GitHub repo</li> <li>Name your new repository and clone it locally</li> </ul> </li> <li>Customize the content<ul> <li>Edit the <code>docs/</code> folder to add your enablement instructions, labs, and resources</li> <li>Update <code>.devcontainer/devcontainer.json</code> to add dependencies or secrets as needed</li> </ul> </li> <li>Launch in Codespaces<ul> <li>Click the Code button in your repo and select \"Open with Codespaces\"</li> <li>Your environment will be ready in seconds, with all tools and docs pre-installed</li> </ul> </li> <li>Publish documentation<ul> <li>Use the <code>installMKdocs</code> function to install MkDocs inside the container and serve the documentation locally on port 8000, making it easy to write and preview your documentation.</li> <li>Push changes to <code>main</code> to trigger GitHub Pages deployment (see Actions tab)</li> <li>Your docs will be live at <code>https://&lt;your-org&gt;.github.io/&lt;your-repo&gt;/</code></li> </ul> </li> </ol>"},{"location":"template/#todos-in-the-codebase","title":"\ud83d\udcdd TODOs in the Codebase","text":"<p>Throughout the template repository, you will find <code>TODO</code> comments in various files. These guide you step-by-step as you create your own enablements\u2014reminding you where to add content, configure secrets, or customize scripts.</p> <p>Tip: To make working with TODOs easier, install a TODO highlighting extension in VS Code, such as TODO Highlight or TODO Tree. These extensions help you quickly find and manage all TODOs in your project.</p> <p>By following and resolving these TODOs, you can efficiently adapt the template to your specific enablement scenario.</p>"},{"location":"template/#who-is-this-for","title":"\ud83e\uddd1\u200d\ud83c\udfeb Who is this for?","text":"<ul> <li>Trainers and educators creating hands-on labs</li> <li>Solution architects building demo environments</li> <li>Anyone seeking a fast, reproducible Codespaces-based enablement</li> </ul>"},{"location":"template/#documentation-resources","title":"\ud83d\udcda Documentation &amp; Resources","text":"<ul> <li>Template Repository</li> <li>How to use the Codespaces Template</li> </ul> <ul> <li>Let's continue</li> </ul>"},{"location":"testing/","title":"9. Testing","text":"<p>Quality Assurance</p> <p>To maintain high standards across all repositories using the enablement framework, a robust testing strategy is enforced. This ensures every repository remains reliable, consistent, and production-ready.</p>"},{"location":"testing/#integration-testing-on-pull-requests","title":"\ud83e\uddea Integration Testing on Pull Requests","text":"<ul> <li> <p>Automated Integration Tests:   Every repository must include integration tests that run automatically on every Pull Request (PR). This ensures new changes do not break existing functionality.</p> </li> <li> <p>integration.sh Script:   The core of the testing process is the <code>integration.sh</code> script, located in the root of each repository. This script is adapted as needed and is triggered by a GitHub Actions workflow on every PR.</p> </li> <li>The workflow provisions a full Codespace environment, deploying all required applications and dependencies.</li> <li> <p>Once the environment is ready, <code>integration.sh</code> runs a series of assertions to verify that applications and pods are running as expected in their respective namespaces.</p> </li> <li> <p>On-Demand Testing:   Integration tests can also be executed manually at any time using the <code>runIntegrationTests</code> function, allowing developers to validate changes before submitting a PR.</p> </li> </ul>"},{"location":"testing/#example-integrationsh","title":"Example: integration.sh","text":"integration.sh<pre><code>#!/bin/bash\n# Load framework\nsource .devcontainer/util/source_framework.sh\n\nprintInfoSection \"Running integration tests for $RepositoryName\"\n\nassertRunningPod dynatrace operator\n\nassertRunningPod dynatrace activegate\n\nassertRunningPod dynatrace oneagent\n\nassertRunningPod todoapp todoapp\n\nassertRunningApp 30100\n</code></pre>"},{"location":"testing/#git-strategy","title":"Git Strategy","text":"<p>Git Strategy &amp; GitHub Actions Workflow</p> <p></p>"},{"location":"testing/#branch-protection","title":"\ud83d\udd12 Branch Protection","text":"<p>Main Branch Protection:   The <code>main</code> branch is protected and will only accept PRs that pass all integration tests. This ensures only thoroughly tested code is merged, maintaining the integrity of the repository.</p>"},{"location":"testing/#integration-test-badges","title":"\ud83d\udee1\ufe0f Integration Test Badges","text":"<p>All repositories in the enablement framework display an integration test badge to show the current status of their automated tests. This badge provides immediate visibility into the health of each repository.</p> <p>For example, the badge for this repository is:</p> <p></p> <p>You can find a table with all enablement framework repositories and their current integration test status in the README section of this repository.</p> <p>By following these standards, the enablement framework enforces continuous quality assurance and reliability across all managed repositories.</p> <ul> <li>Continue to Monitoring \u2192</li> </ul>"},{"location":"user-experience/","title":"7. User Experience","text":"<p>Maximizing User Experience with ease of use, best practices, readable code, DevOps tooling, and more...</p> <p></p> <p>To maximize adoption and uphold the Dynatrace public image\u2014especially among DevOps stakeholders\u2014repositories using the enablement framework should follow these best practices:</p> <ul> <li>Present all materials and interfaces professionally and consistently.</li> <li>Govern the project with a clear, recognized open source license.</li> <li>Tag stable releases to provide clear versioning and facilitate reliable adoption.</li> <li>Maintain comprehensive, up-to-date changelogs to document project evolution.</li> <li>Structure code for readability and scalability, supporting maintainability and future growth.</li> <li>Provide clean, well-organized, and accessible documentation for all users.</li> <li>Respond promptly and constructively to issues and community feedback.</li> <li>Use inclusive language throughout documentation and communications.</li> <li>Display relevant badges (build status, license, coverage) to communicate project health and transparency.</li> <li>Incorporate recognizable logos to reinforce project identity.</li> <li>Offer interactive, hands-on training resources to accelerate onboarding and skill development.</li> <li>Recommend tools such as p10k, k9s, and zsh to further enhance the DevOps experience.</li> </ul> <p>By following these guidelines, the framework remains accessible, professional, and appealing to the broader DevOps and open source communities.</p>"},{"location":"user-experience/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"user-experience/#navigating-the-kubernetes-cluster-with-k9s","title":"\ud83e\uddc8 Navigating the Kubernetes Cluster with k9s","text":"<p>One of the most efficient ways to interact with your Kubernetes cluster is by using <code>k9s</code>, a terminal-based UI that streamlines cluster management and troubleshooting.</p> <p>K9s in action</p> <p></p> <p>Getting Started with k9s:</p> <ul> <li>Launch <code>k9s</code> by running <code>k9s</code> in your terminal (pre-installed in the Codespaces Enablement Framework).</li> <li>The interface provides a real-time, interactive view of all your Kubernetes resources\u2014pods, deployments, services, and more.</li> <li>Use the arrow keys to navigate, <code>/</code> to filter resources, and <code>:</code> to enter commands (e.g., <code>:ctx</code> to switch contexts, <code>:ns</code> to change namespaces, <code>:pod</code> to list pods, <code>:svc</code> to list services, <code>:dynakube</code> to list dynakubes).</li> <li>Press <code>d</code> to describe a resource, <code>l</code> to view logs, and <code>s</code> to open a shell into a pod.</li> <li>Press <code>0</code> (zero) to list all resources, namespaces, and services.</li> <li>All actions are keyboard-driven, making it fast and intuitive for both power users and beginners.</li> </ul> <p>Why use k9s?</p> <ul> <li>Rapidly diagnose issues, monitor workloads, and manage resources without leaving your terminal.</li> <li>Visualize pod health, events, and logs in real time.</li> <li>Reduce context switching and streamline your DevOps workflow.</li> </ul> <p>For more details, see the k9s documentation or try it out in your Codespace now.</p> <ul> <li>Continue to Synchronizer \u2192</li> </ul>"},{"location":"whats-next/","title":"13. What's next?","text":"<p>Now that you've explored the framework and best practices, you can:</p> <ul> <li>Create your own enablement from the template repository and start building with the enablement framework.</li> <li>Learn from existing enablements by exploring the repositories below. Each repository demonstrates a specific use case or advanced scenario.</li> </ul> <p>Explore these repositories to deepen your knowledge or use them as a foundation for your own projects. Find the full list and latest updates in the codespaces-framework repository.</p> <p>More to come</p> <ul> <li>Stay tuned, more enablements are coming with more advanced use cases...</li> </ul>"},{"location":"snippets/admonitions/","title":"Admonitions","text":"<p>Note</p> <p>This is a Note </p> <p>Abstract</p> <p>This is an abstract</p> <p>Tipp</p> <p>This is a tipp </p> <p>Success</p> <p>This is a success </p> <p>Question</p> <p>This is a success </p> <p>Failure</p> <p>This is a failure </p> <p>Danger</p> <p>This is a danger </p> <p>Info</p> <p>This is a info</p> <p>Warning</p> <p>This is a Warning </p> <p>This is an Example admonition</p> <p>This is an example</p> This is a bug and is collapsable <p>This is a bug</p>"},{"location":"snippets/disclaimer/","title":"Disclaimer","text":"<p>Support Policy</p> <p>This is an enablement project created by the Center of Excellence - Enablement Team at Dynatrace.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"snippets/dt-enablement/","title":"Dt enablement","text":"<p>This Codespace leverages the Dynatrace Enablement Framework, providing a robust and flexible development environment. Key features include:</p> <ul> <li>Seamless operation within GitHub Codespaces, as a remote container, or locally via Docker.</li> <li>Cross-compilation support for both AMD and ARM architectures, ensuring broad compatibility.</li> <li>Adherence to industry standards and best practices to optimize the developer experience.</li> <li>Real-time observability of Kubernetes clusters using Dynatrace Full-Stack monitoring.</li> <li>Integrated Dynatrace MCP Server to deliver deep, actionable insights across distributed systems.</li> </ul> <p>To learn more about the Dynatrace Enablement Framework and how it can enhance your development workflow, please refer to the official documentation </p>"},{"location":"snippets/grail-requirements/","title":"Grail requirements","text":"<p>Requirements</p> <ul> <li>A Grail enabled Dynatrace SaaS Tenant (sign up here).</li> <li>A GitHub account to interact with the demo repository.</li> </ul>"},{"location":"snippets/view-code/","title":"View code","text":"<p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p>"}]}